<!DOCTYPE html>
<!--********************************************-->
<!--*       Generated from PreTeXt source      *-->
<!--*                                          *-->
<!--*         https://pretextbook.org          *-->
<!--*                                          *-->
<!--********************************************-->
<html lang="en-US">
<head xmlns:og="http://ogp.me/ns#" xmlns:book="https://ogp.me/ns/book#">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<title>Orthogonal projection</title>
<meta name="Keywords" content="Authored in PreTeXt">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta property="og:type" content="book">
<meta property="book:title" content="Linear algebra: the theory of vector spaces and linear transformations">
<meta property="book:author" content="Aaron Greicius">
<script src="https://sagecell.sagemath.org/static/embedded_sagecell.js"></script><script>var runestoneMathReady = new Promise((resolve) => window.rsMathReady = resolve);
window.MathJax = {
  tex: {
    inlineMath: [['\\(','\\)']],
    tags: "none",
    tagSide: "right",
    tagIndent: ".8em",
    packages: {'[+]': ['base', 'extpfeil', 'ams', 'amscd', 'color', 'newcommand', 'knowl']}
  },
  options: {
    ignoreHtmlClass: "tex2jax_ignore|ignore-math",
    processHtmlClass: "process-math",
    renderActions: {
        findScript: [10, function (doc) {
            document.querySelectorAll('script[type^="math/tex"]').forEach(function(node) {
                var display = !!node.type.match(/; *mode=display/);
                var math = new doc.options.MathItem(node.textContent, doc.inputJax[0], display);
                var text = document.createTextNode('');
                node.parentNode.replaceChild(text, node);
                math.start = {node: text, delim: '', n: 0};
                math.end = {node: text, delim: '', n: 0};
                doc.math.push(math);
            });
        }, '']
    },
  },
  chtml: {
    scale: 0.98,
    mtextInheritFont: true
  },
  loader: {
    load: ['input/asciimath', '[tex]/extpfeil', '[tex]/amscd', '[tex]/color', '[tex]/newcommand', '[pretext]/mathjaxknowl3.js'],
    paths: {pretext: "https://pretextbook.org/js/lib"},
  },
  startup: {
    pageReady() {
      return MathJax.startup.defaultPageReady().then(function () {
      console.log("in ready function");
      rsMathReady();
      }
    )}
  },
};
</script><script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script><link href="https://webwork-ptx.aimath.org/webwork2_files/js/apps/MathView/mathview.css" rel="stylesheet">
<script src="https://pretextbook.org/js/0.3/pretext-webwork/2.17/pretext-webwork.js"></script><script src="https://webwork-ptx.aimath.org/webwork2_files/node_modules/iframe-resizer/js/iframeResizer.min.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lunr.js/2.3.9/lunr.min.js" integrity="sha512-4xUl/d6D6THrAnXAwGajXkoWaeMNwEKK4iNfq5DotEbLPAfk6FSxSP3ydNxqDgCw1c/0Z1Jg6L8h2j+++9BZmg==" crossorigin="anonymous" referrerpolicy="no-referrer"></script><script src="lunr-pretext-search-index.js" async=""></script><script src="https://pretextbook.org/js/0.3/pretext_search.js"></script><link href="https://pretextbook.org/css/0.7/pretext_search.css" rel="stylesheet" type="text/css">
<script>js_version = 0.3</script><script src="https://pretextbook.org/js/lib/jquery.min.js"></script><script src="https://pretextbook.org/js/lib/jquery.sticky.js"></script><script src="https://pretextbook.org/js/lib/jquery.espy.min.js"></script><script src="https://pretextbook.org/js/0.3/pretext.js"></script><script>miniversion=0.1</script><script src="https://pretextbook.org/js/0.3/pretext_add_on.js?x=1"></script><script src="https://pretextbook.org/js/0.3/user_preferences.js"></script><script src="https://pretextbook.org/js/lib/knowl.js"></script><!--knowl.js code controls Sage Cells within knowls--><script>sagecellEvalName='Evaluate (Sage)';
</script><link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="">
<link href="https://fonts.googleapis.com/css2?family=Inconsolata:wght@400;700&amp;family=Noto+Serif:ital,wght@0,400;0,700;1,400;1,700&amp;family=Tinos:ital,wght@0,400;0,700;1,400;1,700&amp;display=swap" rel="stylesheet">
<link href="https://fonts.cdnfonts.com/css/dejavu-serif" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Roboto+Serif:opsz,wdth,wght@8..144,50..150,100..900&amp;display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Open+Sans:wdth,wght@75..100,300..800&amp;display=swap" rel="stylesheet">
<link href="https://pretextbook.org/css/0.7/pretext.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/pretext_add_on.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/shell_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/banner_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/navbar_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/toc_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/knowls_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/style_default.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/colors_blue_red.css" rel="stylesheet" type="text/css">
<link href="https://pretextbook.org/css/0.7/setcolors.css" rel="stylesheet" type="text/css">
</head>
<body class="pretext book ignore-math">
<a class="assistive" href="#ptx-content">Skip to main content</a><header id="ptx-masthead" class="ptx-masthead"><div class="ptx-banner">
<a id="logo-link" class="logo-link" href="http://linear-algebra.northwestern.pub/" target="_blank"><img src="external/images/im_holycomm.svg" alt="Logo image"></a><div class="title-container">
<h1 class="heading"><a href="book-1.html"><span class="title">Linear algebra: the theory of vector spaces and linear transformations</span></a></h1>
<p class="byline">Aaron Greicius</p>
</div>
<div id="searchresultsplaceholder" class="searchresultsplaceholder" style="display: none">
<button id="closesearchresults" class="closesearchresults" onclick="document.getElementById('searchresultsplaceholder').style.display = 'none'; return false;">x</button><h2>Search Results: <span id="searchterms" class="searchterms"></span>
</h2>
<div id="searchempty" class="searchempty"><span>No results.</span></div>
<ol id="searchresults" class="searchresults"></ol>
</div>
</div></header><nav id="ptx-navbar" class="ptx-navbar navbar"><button class="toc-toggle button" aria-label="Show or hide table of contents"><span class="icon">‚ò∞</span><span class="name">Contents</span></button><a class="index-button button" href="index-1.html" title="Index"><span class="name">Index</span></a><button id="user-preferences-button" class="user-preferences-button button" title="Modify user preferences"><span id="avatarbutton" class="avatarbutton name">You!</span><div id="preferences_menu_holder" class="preferences_menu_holder hidden"><ol id="preferences_menu" class="preferences_menu" style="font-family: 'Roboto Serif', serif;">
<li data-env="avatar" tabindex="-1">Choose avatar<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden avatar">
<li data-val="You!" tabindex="-1">
<span id="theYou!" class="avatarcheck">‚úîÔ∏è</span>You!</li>
<li data-val="üò∫" tabindex="-1">
<span id="theüò∫" class="avatarcheck"></span>üò∫</li>
<li data-val="üë§" tabindex="-1">
<span id="theüë§" class="avatarcheck"></span>üë§</li>
<li data-val="üëΩ" tabindex="-1">
<span id="theüëΩ" class="avatarcheck"></span>üëΩ</li>
<li data-val="üê∂" tabindex="-1">
<span id="theüê∂" class="avatarcheck"></span>üê∂</li>
<li data-val="üêº" tabindex="-1">
<span id="theüêº" class="avatarcheck"></span>üêº</li>
<li data-val="üåà" tabindex="-1">
<span id="theüåà" class="avatarcheck"></span>üåà</li>
</ol>
</li>
<li data-env="fontfamily" tabindex="-1">Font family<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden fontfamily">
<li data-val="face" data-change="OS" tabindex="-1" style="font-family: 'Open Sans'">
<span id="theOS" class="ffcheck">‚úîÔ∏è</span><span class="name">Open Sans</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
<li data-val="face" data-change="RS" tabindex="-1" style="font-family: 'Roboto Serif'">
<span id="theRS" class="ffcheck"></span><span class="name">Roboto Serif</span><span class="sample">AaBbCc 123 PreTeXt</span>
</li>
</ol>
</li>
<li data-env="font" tabindex="-1">Adjust font<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden fonts">
<li>Size</li>
<li><span id="thesize">12</span></li>
<li data-val="size" data-change="-1" tabindex="-1" style="font-size: 80%">Smaller</li>
<li data-val="size" data-change="1" tabindex="-1" style="font-size: 110%">Larger</li>
<li>Width</li>
<li><span id="thewdth">100</span></li>
<li data-val="wdth" data-change="-5" tabindex="-1" style="font-variation-settings: 'wdth' 60">narrower</li>
<li data-val="wdth" data-change="5" tabindex="-1" style="font-variation-settings: 'wdth' 150">wider</li>
<li>Weight</li>
<li><span id="thewght">400</span></li>
<li data-val="wght" data-change="-50" tabindex="-1" style="font-weight: 200">thinner</li>
<li data-val="wght" data-change="50" tabindex="-1" style="font-weight: 700">heavier</li>
<li>Letter spacing</li>
<li>
<span id="thelspace">0</span><span class="byunits">/200</span>
</li>
<li data-val="lspace" data-change="-1" tabindex="-1">closer</li>
<li data-val="lspace" data-change="1" tabindex="-1">f a r t h e r</li>
<li>Word spacing</li>
<li>
<span id="thewspace">0</span><span class="byunits">/50</span>
</li>
<li data-val="wspace" data-change="-1" tabindex="-1">smaller‚ÄÖgap‚ÄÉ</li>
<li data-val="wspace" data-change="1" tabindex="-1">larger‚ÄÉgap</li>
<li>Line Spacing</li>
<li>
<span id="theheight">135</span><span class="byunits">/100</span>
</li>
<li data-val="height" data-change="-5" tabindex="-1" style="line-height: 1">closer<br>together</li>
<li data-val="height" data-change="5" tabindex="-1" style="line-height: 1.75">further<br>apart</li>
</ol>
</li>
<li data-env="atmosphere" tabindex="-1">Light/dark mode<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden atmosphere">
<li data-val="default" tabindex="-1">
<span id="thedefault" class="atmospherecheck">‚úîÔ∏è</span>default</li>
<li data-val="pastel" tabindex="-1">
<span id="thepastel" class="atmospherecheck"></span>pastel</li>
<li data-val="darktwilight" tabindex="-1">
<span id="thedarktwilight" class="atmospherecheck"></span>twilight</li>
<li data-val="dark" tabindex="-1">
<span id="thedark" class="atmospherecheck"></span>dark</li>
<li data-val="darkmidnight" tabindex="-1">
<span id="thedarkmidnight" class="atmospherecheck"></span>midnight</li>
</ol>
</li>
<li data-env="ruler" tabindex="-1">Reading ruler<div class="wrap_to_submenu"><span class="to_submenu">‚ñª</span></div>
<ol class="hidden ruler">
<li data-val="none" tabindex="-1">
<span id="thenone" class="rulercheck">‚úîÔ∏è</span>none</li>
<li data-val="underline" tabindex="-1">
<span id="theunderline" class="rulercheck"></span>underline</li>
<li data-val="lunderline" tabindex="-1">
<span id="thelunderline" class="rulercheck"></span>L-underline</li>
<li data-val="greybar" tabindex="-1">
<span id="thegreybar" class="rulercheck"></span>grey bar</li>
<li data-val="lightbox" tabindex="-1">
<span id="thelightbox" class="rulercheck"></span>light box</li>
<li data-val="sunrise" tabindex="-1">
<span id="thesunrise" class="rulercheck"></span>sunrise</li>
<li data-val="sunriseunderline" tabindex="-1">
<span id="thesunriseunderline" class="rulercheck"></span>sunrise underline</li>
<li class="moveQ">Motion by:</li>
<li data-val="mouse" tabindex="-1">
<span id="themouse" class="motioncheck">‚úîÔ∏è</span>follow the mouse</li>
<li data-val="arrow" tabindex="-1">
<span id="thearrow" class="motioncheck"></span>up/down arrows - not yet</li>
<li data-val="eye" tabindex="-1">
<span id="theeye" class="motioncheck"></span>eye tracking - not yet</li>
</ol>
</li>
</ol></div></button><span class="treebuttons"><a class="previous-button button" href="s_orthogonality.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="up-button button" href="c_innerproductspaces.html" title="Up"><span class="icon">^</span><span class="name">Up</span></a><a class="next-button button" href="c_transbasis.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a></span><div class="searchbox"><div class="searchwidget">
<input id="ptxsearch" class="ptxsearch" type="text" name="terms" placeholder="Search" onchange="doSearch()"><button id="searchbutton" class="searchbutton" type="button" onclick="doSearch()">üîç</button>
</div></div></nav><div id="latex-macros" class="hidden-content process-math" style="display:none"><span class="process-math">\(\require{cancel}\newcommand{\Z}{{\mathbb Z}}
\newcommand{\Q}{{\mathbb Q}}
\newcommand{\R}{{\mathbb R}}
\newcommand{\C}{{\mathbb C}}
\newcommand{\T}{{\mathbb T}}
\newcommand{\F}{{\mathbb F}}
\newcommand{\HH}{{\mathbb H}}
\newcommand{\compose}{\circ}
\newcommand{\bolda}{{\mathbf a}}
\newcommand{\boldb}{{\mathbf b}}
\newcommand{\boldc}{{\mathbf c}}
\newcommand{\boldd}{{\mathbf d}}
\newcommand{\bolde}{{\mathbf e}}
\newcommand{\boldi}{{\mathbf i}}
\newcommand{\boldj}{{\mathbf j}}
\newcommand{\boldk}{{\mathbf k}}
\newcommand{\boldn}{{\mathbf n}}
\newcommand{\boldp}{{\mathbf p}}
\newcommand{\boldq}{{\mathbf q}}
\newcommand{\boldr}{{\mathbf r}}
\newcommand{\bolds}{{\mathbf s}}
\newcommand{\boldt}{{\mathbf t}}
\newcommand{\boldu}{{\mathbf u}}
\newcommand{\boldv}{{\mathbf v}}
\newcommand{\boldw}{{\mathbf w}}
\newcommand{\boldx}{{\mathbf x}}
\newcommand{\boldy}{{\mathbf y}}
\newcommand{\boldz}{{\mathbf z}}
\newcommand{\boldzero}{{\mathbf 0}}
\newcommand{\boldmod}{\boldsymbol{ \bmod }}
\newcommand{\boldT}{{\mathbf T}}
\newcommand{\boldN}{{\mathbf N}}
\newcommand{\boldB}{{\mathbf B}}
\newcommand{\boldF}{{\mathbf F}}
\newcommand{\boldS}{{\mathbf S}}
\newcommand{\boldG}{{\mathbf G}}
\newcommand{\boldK}{{\mathbf K}}
\newcommand{\boldL}{{\mathbf L}}
\DeclareMathOperator{\lcm}{lcm}
\DeclareMathOperator{\Span}{span}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\NS}{null}
\DeclareMathOperator{\RS}{row}
\DeclareMathOperator{\CS}{col}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\range}{range}
\DeclareMathOperator{\rank}{rank}
\DeclareMathOperator{\nullity}{nullity}
\DeclareMathOperator{\sign}{sign}
\DeclareMathOperator{\Fix}{Fix}
\DeclareMathOperator{\Aff}{Aff}
\DeclareMathOperator{\Frac}{Frac}
\DeclareMathOperator{\Ann}{Ann}
\DeclareMathOperator{\Tor}{Tor}
\DeclareMathOperator{\id}{id}
\DeclareMathOperator{\mdeg}{mdeg}
\DeclareMathOperator{\Lt}{Lt}
\DeclareMathOperator{\Lc}{Lc}
\DeclareMathOperator{\disc}{disc}
\DeclareMathOperator{\Frob}{Frob}
\DeclareMathOperator{\adj}{adj}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\diver}{div}
\DeclareMathOperator{\flux}{flux}
\def\Gal{\operatorname{Gal}}
\def\ord{\operatorname{ord}}
\def\ML{\operatorname{M}}
\def\GL{\operatorname{GL}}
\def\PGL{\operatorname{PGL}}
\def\SL{\operatorname{SL}}
\def\PSL{\operatorname{PSL}}
\def\GSp{\operatorname{GSp}}
\def\PGSp{\operatorname{PGSp}}
\def\Sp{\operatorname{Sp}}
\def\PSp{\operatorname{PSp}}
\def\Aut{\operatorname{Aut}}
\def\Inn{\operatorname{Inn}}
\def\Hom{\operatorname{Hom}}
\def\End{\operatorname{End}}
\def\ch{\operatorname{char}}
\def\Zp{\Z/p\Z}
\def\Zm{\Z/m\Z}
\def\Zn{\Z/n\Z}
\def\Fp{\F_p}
\newcommand{\surjects}{\twoheadrightarrow}
\newcommand{\injects}{\hookrightarrow}
\newcommand{\bijects}{\leftrightarrow}
\newcommand{\isomto}{\overset{\sim}{\rightarrow}}
\newcommand{\floor}[1]{\lfloor#1\rfloor}
\newcommand{\ceiling}[1]{\left\lceil#1\right\rceil}
\newcommand{\mclass}[2][m]{[#2]_{#1}}
\newcommand{\val}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\abs}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\valuation}[2][]{\left\lvert #2\right\rvert_{#1}}
\newcommand{\norm}[1]{\left\lVert#1\right\rVert}
\newcommand{\anpoly}{a_nx^n+a_{n-1}x^{n-1}\cdots +a_1x+a_0}
\newcommand{\anmonic}{x^n+a_{n-1}x^{n-1}\cdots +a_1x+a_0}
\newcommand{\bmpoly}{b_mx^m+b_{m-1}x^{m-1}\cdots +b_1x+b_0}
\newcommand{\bnpoly}{b_nx^n+b_{n-1}x^{n-1}\cdots +b_1x+b_0}
\newcommand{\pder}[2]{\frac{\partial#1}{\partial#2}}
\newcommand{\normalin}{\trianglelefteq}
\newcommand{\angvec}[1]{\langle #1\rangle}
\newcommand{\varpoly}[2]{#1_{#2}x^{#2}+#1_{#2-1}x^{#2-1}\cdots +#1_1x+#1_0}
\newcommand{\varpower}[1][a]{#1_0+#1_1x+#1_1x^2+\cdots}
\newcommand{\limasto}[2][x]{\lim_{#1\rightarrow #2}}
\def\ntoinfty{\lim_{n\rightarrow\infty}}
\def\xtoinfty{\lim_{x\rightarrow\infty}}
\def\ii{\item}
\def\bb{\begin{enumerate}}
\def\ee{\end{enumerate}}
\def\ds{\displaystyle}
\def\p{\partial}
\newcommand{\abcdmatrix}[4]{\begin{bmatrix}#1\amp #2\\ #3\amp #4 \end{bmatrix}
}
\newenvironment{amatrix}[1][ccc|c]{\left[\begin{array}{#1}}{\end{array}\right]}
\newenvironment{linsys}[2][m]{
\begin{array}[#1]{@{}*{#2}{rc}r@{}}
}{
\end{array}}
\newcommand{\eqsys}{\begin{array}{rcrcrcr}
a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp b_1\\
a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp b_2\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \\
a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp b_m
\end{array}
}
\newcommand{\numeqsys}{\begin{array}{rrcrcrcr}
e_1:\amp  a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp b_1\\
e_2: \amp a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp b_2\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp  \\
e_m: \amp a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp b_m
\end{array}
}
\newcommand{\homsys}{\begin{array}{rcrcrcr}
a_{11}x_{1}\amp +\amp a_{12}x_{2}\amp +\cdots+\amp  a_{1n}x_{n}\amp =\amp 0\\
a_{21}x_{1}\amp +\amp a_{22}x_{2}\amp +\cdots+\amp a_{2n}x_{n}\amp =\amp 0\\
\amp \vdots\amp   \amp \vdots \amp  \amp \vdots \amp \\
a_{m1}x_{1}\amp +\amp a_{m2}x_{2}\amp +\cdots +\amp a_{mn}x_{n}\amp =\amp 0
\end{array}
}
\newcommand{\vareqsys}[4]{
\begin{array}{ccccccc}
#3_{11}x_{1}\amp +\amp #3_{12}x_{2}\amp +\cdots+\amp  #3_{1#2}x_{#2}\amp =\amp #4_1\\
#3_{21}x_{1}\amp +\amp #3_{22}x_{2}\amp +\cdots+\amp #3_{2#2}x_{#2}\amp =\amp #4_2\\
\vdots \amp \amp \vdots \amp  \amp \vdots \amp =\amp  \\
#3_{#1 1}x_{1}\amp +\amp #3_{#1 2}x_{2}\amp +\cdots +\amp #3_{#1 #2}x_{#2}\amp =\amp #4_{#1}
\end{array}
}
\newcommand{\genmatrix}[1][a]{
\begin{bmatrix}
#1_{11} \amp  #1_{12} \amp  \cdots \amp  #1_{1n} \\
#1_{21} \amp  #1_{22} \amp  \cdots \amp  #1_{2n} \\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \\
#1_{m1} \amp  #1_{m2} \amp  \cdots \amp  #1_{mn}
\end{bmatrix}
}
\newcommand{\varmatrix}[3]{
\begin{bmatrix}
#3_{11} \amp  #3_{12} \amp  \cdots \amp  #3_{1#2} \\
#3_{21} \amp  #3_{22} \amp  \cdots \amp  #3_{2#2} \\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \\
#3_{#1 1} \amp  #3_{#1 2} \amp  \cdots \amp  #3_{#1 #2}
\end{bmatrix}
}
\newcommand{\augmatrix}{
\begin{amatrix}[cccc|c]
a_{11} \amp  a_{12} \amp  \cdots \amp  a_{1n} \amp b_{1}\\
a_{21} \amp  a_{22} \amp  \cdots \amp  a_{2n} \amp b_{2}\\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \amp \vdots\\
a_{m1} \amp  a_{m2} \amp  \cdots \amp  a_{mn}\amp b_{m}
\end{amatrix}
}
\newcommand{\varaugmatrix}[4]{
\begin{amatrix}[cccc|c]
#3_{11} \amp  #3_{12} \amp  \cdots \amp  #3_{1#2} \amp #4_{1}\\
#3_{21} \amp  #3_{22} \amp  \cdots \amp  #3_{2#2} \amp #4_{2}\\
\vdots  \amp  \vdots  \amp  \ddots \amp  \vdots  \amp \vdots\\
#3_{#1 1} \amp  #3_{#1 2} \amp  \cdots \amp  #3_{#1 #2}\amp #4_{#1}
\end{amatrix}
}
\newcommand{\spaceforemptycolumn}{\makebox[\wd\boxofmathplus]{\ }}

\newcommand{\generalmatrix}[3]{
\left(
\begin{array}{cccc}
#1_{1,1}  \amp #1_{1,2}  \amp \ldots  \amp #1_{1,#2}  \\
#1_{2,1}  \amp #1_{2,2}  \amp \ldots  \amp #1_{2,#2}  \\
\amp \vdots                         \\
#1_{#3,1} \amp #1_{#3,2} \amp \ldots  \amp #1_{#3,#2}
\end{array}
\right)  }
\newcommand{\colvec}[2][c]{\begin{amatrix}[#1] #2 \end{amatrix}}
\DeclareMathOperator{\size}{size}
\DeclareMathOperator{\adjoint}{adj}
\DeclareMathOperator{\sgn}{sgn}
\newcommand{\restrictionmap}[2]{{#1}\mathpunct\upharpoonright\hbox{}_{#2}}
\renewcommand{\emptyset}{\varnothing}

\newcommand{\proj}[2]{\mbox{proj}_{#2}({#1}) }
\renewcommand{\Re}{\operatorname{Re}}
 \renewcommand{\Im}{\operatorname{Im}}
\newcommand{\lt}{&lt;}
\newcommand{\gt}{&gt;}
\newcommand{\amp}{&amp;}
\definecolor{fillinmathshade}{gray}{0.9}
\newcommand{\fillinmath}[1]{\mathchoice{\colorbox{fillinmathshade}{$\displaystyle     \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\textstyle        \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptstyle      \phantom{\,#1\,}$}}{\colorbox{fillinmathshade}{$\scriptscriptstyle\phantom{\,#1\,}$}}}
\)</span></div>
<div class="ptx-page">
<div id="ptx-sidebar" class="ptx-sidebar"><nav id="ptx-toc" class="ptx-toc depth2"><ul class="structural">
<li>
<div class="toc-item"><a href="frontmatter-1.html" class="internal"><span class="title">Front Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="colophon-1.html" class="internal"><span class="title">Colophon</span></a></div></li>
<li><div class="toc-item"><a href="acknowledgement-1.html" class="internal"><span class="title">Acknowledgements</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="c_foundations.html" class="internal"><span class="codenumber">0</span> <span class="title">Foundations</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="s_sets_functions.html" class="internal"><span class="codenumber">0.1</span> <span class="title">Sets</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="s_sets_functions.html#s_sets_functions_ex" class="internal"><span class="codenumber">0.1</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="s_functions.html" class="internal"><span class="codenumber">0.2</span> <span class="title">Functions</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="s_functions.html#s_functions_ex" class="internal"><span class="codenumber">0.2</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li><div class="toc-item"><a href="s_tuples.html" class="internal"><span class="codenumber">0.3</span> <span class="title">Tuples and Cartesian products</span></a></div></li>
<li>
<div class="toc-item"><a href="s_logic.html" class="internal"><span class="codenumber">0.4</span> <span class="title">Logic</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_logic.html#ss_propositional_calculus" class="internal"><span class="codenumber">0.4.1</span> <span class="title">Propositional logic</span></a></div></li>
<li><div class="toc-item"><a href="s_logic.html#ss_predicate_logic" class="internal"><span class="codenumber">0.4.2</span> <span class="title">Predicate logic</span></a></div></li>
<li><div class="toc-item"><a href="s_logic.html#s_logic_ex" class="internal"><span class="codenumber">0.4.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_proof_technique.html" class="internal"><span class="codenumber">0.5</span> <span class="title">Proof techniques</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="s_proof_technique.html#ss_logical_structure" class="internal"><span class="codenumber">0.5.1</span> <span class="title">Logical structure</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_proof_technique.html#sss_implication" class="internal"><span class="title">Implication</span></a></div></li>
<li><div class="toc-item"><a href="s_proof_technique.html#sss_disjunction" class="internal"><span class="title">Disjunction</span></a></div></li>
<li><div class="toc-item"><a href="s_proof_technique.html#sss_equivalence" class="internal"><span class="title">Equivalence</span></a></div></li>
<li><div class="toc-item"><a href="s_proof_technique.html#sss_logical_chains" class="internal"><span class="title">Chains of implications/equivalences</span></a></div></li>
<li><div class="toc-item"><a href="s_proof_technique.html#sss_proof_by_contradiction" class="internal"><span class="title">Proof by contradiction</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_proof_technique.html#ss_Equalities" class="internal"><span class="codenumber">0.5.2</span> <span class="title">Equalities</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="s_proof_technique.html#sss_chain_equalities" class="internal"><span class="title">Chain of equalities</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="s_proof_technique.html#ss_set_properties" class="internal"><span class="codenumber">0.5.3</span> <span class="title">Basic set properties</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_proof_technique.html#sss_set_inclusion" class="internal"><span class="title">Set inclusion</span></a></div></li>
<li><div class="toc-item"><a href="s_proof_technique.html#sss_set_equality" class="internal"><span class="title">Set equality</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_proof_technique.html#ss_function_properties" class="internal"><span class="codenumber">0.5.4</span> <span class="title">Basic function properties</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_proof_technique.html#sss_function_equality" class="internal"><span class="title">Function equality</span></a></div></li>
<li><div class="toc-item"><a href="s_proof_technique.html#sss_injective_surjective_bijective" class="internal"><span class="title">Injective, surjective, bijective</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_proof_technique.html#ss_mathematical_induction" class="internal"><span class="codenumber">0.5.5</span> <span class="title">Mathematical induction</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_proof_technique.html#sss_weak_induction" class="internal"><span class="title">Proof by induction</span></a></div></li>
<li><div class="toc-item"><a href="s_proof_technique.html#sss_strong_induction" class="internal"><span class="title">Proof by strong induction</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_complex_numbers.html" class="internal"><span class="codenumber">0.6</span> <span class="title">Complex numbers</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_complex_numbers.html#ss_complex_definition" class="internal"><span class="codenumber">0.6.1</span> <span class="title">Definition of <span class="process-math">\(\C\)</span></span></a></div></li>
<li><div class="toc-item"><a href="s_complex_numbers.html#ss_complex_conjugation" class="internal"><span class="codenumber">0.6.2</span> <span class="title">Absolute value and complex conjugation</span></a></div></li>
<li><div class="toc-item"><a href="s_complex_numbers.html#s_complex_numbers_ex" class="internal"><span class="codenumber">0.6.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_polynomials.html" class="internal"><span class="codenumber">0.7</span> <span class="title">Polynomials</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_polynomials.html#ss_poly_def" class="internal"><span class="codenumber">0.7.1</span> <span class="title">Basic definitions</span></a></div></li>
<li><div class="toc-item"><a href="s_polynomials.html#ss_degree" class="internal"><span class="codenumber">0.7.2</span> <span class="title">Degree of a polynomial</span></a></div></li>
<li><div class="toc-item"><a href="s_polynomials.html#ss_poly_factoring" class="internal"><span class="codenumber">0.7.3</span> <span class="title">Factoring polynomials</span></a></div></li>
<li><div class="toc-item"><a href="s_polynomials.html#s_polynomials_ex" class="internal"><span class="codenumber">0.7.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="c_linear_systems.html" class="internal"><span class="codenumber">1</span> <span class="title">Systems of linear equations</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="s_systems.html" class="internal"><span class="codenumber">1.1</span> <span class="title">Systems of linear equations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_systems.html#ss_linear_equations" class="internal"><span class="codenumber">1.1.1</span> <span class="title">Systems of linear equations</span></a></div></li>
<li><div class="toc-item"><a href="s_systems.html#ss_row_equivalence" class="internal"><span class="codenumber">1.1.2</span> <span class="title">Row operations</span></a></div></li>
<li><div class="toc-item"><a href="s_systems.html#s_systems_ex" class="internal"><span class="codenumber">1.1.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_ge.html" class="internal"><span class="codenumber">1.2</span> <span class="title">Gaussian elimination</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_ge.html#ss_ge_row_echelon" class="internal"><span class="codenumber">1.2.1</span> <span class="title">Row echelon matrices</span></a></div></li>
<li>
<div class="toc-item"><a href="s_ge.html#ss_gaussian_elimination" class="internal"><span class="codenumber">1.2.2</span> <span class="title">Gaussian elimination</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="s_ge.html#subsection-17" class="internal"><span class="title">Model example</span></a></div></li></ul>
</li>
<li><div class="toc-item"><a href="s_ge.html#s_ge_ex" class="internal"><span class="codenumber">1.2.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_solving.html" class="internal"><span class="codenumber">1.3</span> <span class="title">Solving linear systems</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_solving.html#ss_workingExample" class="internal"><span class="codenumber">1.3.1</span> <span class="title">Model example</span></a></div></li>
<li><div class="toc-item"><a href="s_solving.html#ss_solveSystem" class="internal"><span class="codenumber">1.3.2</span> <span class="title">General method for solving linear systems</span></a></div></li>
<li><div class="toc-item"><a href="s_solving.html#s_solving_ex" class="internal"><span class="codenumber">1.3.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="c_matrices.html" class="internal"><span class="codenumber">2</span> <span class="title">Matrices, their arithmetic, and their algebra</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="s_matrix.html" class="internal"><span class="codenumber">2.1</span> <span class="title">Matrix arithmetic</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_matrix.html#ss_matrix_attributes" class="internal"><span class="codenumber">2.1.1</span> <span class="title">The basics</span></a></div></li>
<li><div class="toc-item"><a href="s_matrix.html#ss_matrix_arithmetic" class="internal"><span class="codenumber">2.1.2</span> <span class="title">Addition, subtraction and scalar multiplication</span></a></div></li>
<li><div class="toc-item"><a href="s_matrix.html#ss_matrix_mult" class="internal"><span class="codenumber">2.1.3</span> <span class="title">Matrix multiplication</span></a></div></li>
<li><div class="toc-item"><a href="s_matrix.html#s_column_row_method" class="internal"><span class="codenumber">2.1.4</span> <span class="title">Alternative methods of multiplication</span></a></div></li>
<li><div class="toc-item"><a href="s_matrix.html#subsection-24" class="internal"><span class="codenumber">2.1.5</span> <span class="title">Transpose of a matrix</span></a></div></li>
<li><div class="toc-item"><a href="s_matrix.html#s_matrix_ex" class="internal"><span class="codenumber">2.1.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_algebraic.html" class="internal"><span class="codenumber">2.2</span> <span class="title">Matrix algebra</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="s_algebraic.html#s_algebraic_ex" class="internal"><span class="codenumber">2.2</span> <span class="title">Exercises</span></a></div></li></ul>
</li>
<li>
<div class="toc-item"><a href="s_invertible_matrices.html" class="internal"><span class="codenumber">2.3</span> <span class="title">Invertible matrices</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_invertible_matrices.html#subsec-" class="internal"><span class="codenumber">2.3.1</span> <span class="title">Invertible matrices</span></a></div></li>
<li><div class="toc-item"><a href="s_invertible_matrices.html#subsection-26" class="internal"><span class="codenumber">2.3.2</span> <span class="title">Powers of matrices, matrix polynomials</span></a></div></li>
<li><div class="toc-item"><a href="s_invertible_matrices.html#s_invertible_matrices_ex" class="internal"><span class="codenumber">2.3.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_invertibility_theorem.html" class="internal"><span class="codenumber">2.4</span> <span class="title">The invertibility theorem</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_invertibility_theorem.html#ss_elementary_matrix" class="internal"><span class="codenumber">2.4.1</span> <span class="title">Elementary matrices</span></a></div></li>
<li><div class="toc-item"><a href="s_invertibility_theorem.html#ss_systems_to_matrix_eqns" class="internal"><span class="codenumber">2.4.2</span> <span class="title">Interlude on matrix equations</span></a></div></li>
<li><div class="toc-item"><a href="s_invertibility_theorem.html#ss_invertibility_th" class="internal"><span class="codenumber">2.4.3</span> <span class="title">The invertibility theorem</span></a></div></li>
<li><div class="toc-item"><a href="s_invertibility_theorem.html#ss_invertibility_alg" class="internal"><span class="codenumber">2.4.4</span> <span class="title">Invertibility algorithms</span></a></div></li>
<li><div class="toc-item"><a href="s_invertibility_theorem.html#ss_inv_alg_example" class="internal"><span class="codenumber">2.4.5</span> <span class="title">In-depth example</span></a></div></li>
<li><div class="toc-item"><a href="s_invertibility_theorem.html#ss_invertible_loose_ends" class="internal"><span class="codenumber">2.4.6</span> <span class="title">Some theoretical loose ends</span></a></div></li>
<li><div class="toc-item"><a href="s_invertibility_theorem.html#s_invertibility_theorem_ex" class="internal"><span class="codenumber">2.4.7</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_det.html" class="internal"><span class="codenumber">2.5</span> <span class="title">The determinant</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_det.html#ss_det" class="internal"><span class="codenumber">2.5.1</span> <span class="title">Definition of the determinant</span></a></div></li>
<li><div class="toc-item"><a href="s_det.html#ss_expansion_rows_columns" class="internal"><span class="codenumber">2.5.2</span> <span class="title">Expansion along rows and columns</span></a></div></li>
<li><div class="toc-item"><a href="s_det.html#ss_det_row_ops" class="internal"><span class="codenumber">2.5.3</span> <span class="title">Row operations and determinant</span></a></div></li>
<li><div class="toc-item"><a href="s_det.html#s_det_ex" class="internal"><span class="codenumber">2.5.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="c_vectorspace.html" class="internal"><span class="codenumber">3</span> <span class="title">Vector spaces and linear transformations</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="s_vectorspace.html" class="internal"><span class="codenumber">3.1</span> <span class="title">Real vector spaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_vectorspace.html#ss_vector_space" class="internal"><span class="codenumber">3.1.1</span> <span class="title">Definition of a vector space</span></a></div></li>
<li><div class="toc-item"><a href="s_vectorspace.html#ss_vectorspace_examples" class="internal"><span class="codenumber">3.1.2</span> <span class="title">Examples</span></a></div></li>
<li><div class="toc-item"><a href="s_vectorspace.html#ss_vectorspace_properties" class="internal"><span class="codenumber">3.1.3</span> <span class="title">General properties</span></a></div></li>
<li><div class="toc-item"><a href="s_vectorspace.html#s_vectorspace_ex" class="internal"><span class="codenumber">3.1.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_transformation.html" class="internal"><span class="codenumber">3.2</span> <span class="title">Linear transformations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_transformation.html#ss_linear_transform" class="internal"><span class="codenumber">3.2.1</span> <span class="title">Linear transformations</span></a></div></li>
<li><div class="toc-item"><a href="s_transformation.html#ss_matrix_transforms" class="internal"><span class="codenumber">3.2.2</span> <span class="title">Matrix transformations</span></a></div></li>
<li><div class="toc-item"><a href="s_transformation.html#ss_rotations_reflections" class="internal"><span class="codenumber">3.2.3</span> <span class="title">Rotations and reflections in the plane</span></a></div></li>
<li><div class="toc-item"><a href="s_transformation.html#ss_transform_exotic_examples" class="internal"><span class="codenumber">3.2.4</span> <span class="title">Additional examples</span></a></div></li>
<li><div class="toc-item"><a href="s_transformation.html#ss_transform_composition" class="internal"><span class="codenumber">3.2.5</span> <span class="title">Composition of linear transformations and matrix multiplication</span></a></div></li>
<li><div class="toc-item"><a href="s_transformation.html#s_transformation_ex" class="internal"><span class="codenumber">3.2.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_subspace.html" class="internal"><span class="codenumber">3.3</span> <span class="title">Subspaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_subspace.html#ss_subspace" class="internal"><span class="codenumber">3.3.1</span> <span class="title">Definition of subspace</span></a></div></li>
<li><div class="toc-item"><a href="s_subspace.html#ss_subspaces_tuples" class="internal"><span class="codenumber">3.3.2</span> <span class="title">Subspaces of <span class="process-math">\(\R^n\)</span></span></a></div></li>
<li><div class="toc-item"><a href="s_subspace.html#ss_subspace_matrices" class="internal"><span class="codenumber">3.3.3</span> <span class="title">Important subspaces of <span class="process-math">\(M_{nn}\)</span></span></a></div></li>
<li><div class="toc-item"><a href="s_subspace.html#ss_subspace_functions" class="internal"><span class="codenumber">3.3.4</span> <span class="title">Important subspaces of <span class="process-math">\(F(X,\R)\)</span></span></a></div></li>
<li><div class="toc-item"><a href="s_subspace.html#s_subspace_ex" class="internal"><span class="codenumber">3.3.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_nullspace_image.html" class="internal"><span class="codenumber">3.4</span> <span class="title">Null space and image</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_nullspace_image.html#ss_nullspace_image" class="internal"><span class="codenumber">3.4.1</span> <span class="title">Null space and image of a linear transformation</span></a></div></li>
<li><div class="toc-item"><a href="s_nullspace_image.html#ss_injective_surjective_transforms" class="internal"><span class="codenumber">3.4.2</span> <span class="title">Injective and surjective linear transformations</span></a></div></li>
<li><div class="toc-item"><a href="s_nullspace_image.html#s_nullspace_image_ex" class="internal"><span class="codenumber">3.4.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_span_independence.html" class="internal"><span class="codenumber">3.5</span> <span class="title">Span and linear independence</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_span_independence.html#subsection-50" class="internal"><span class="codenumber">3.5.1</span> <span class="title">Span</span></a></div></li>
<li><div class="toc-item"><a href="s_span_independence.html#ss_linear_independence" class="internal"><span class="codenumber">3.5.2</span> <span class="title">Linear independence</span></a></div></li>
<li><div class="toc-item"><a href="s_span_independence.html#ss_linear_independence_functionspace" class="internal"><span class="codenumber">3.5.3</span> <span class="title">Linear independence in function spaces</span></a></div></li>
<li><div class="toc-item"><a href="s_span_independence.html#s_span_independence_ex" class="internal"><span class="codenumber">3.5.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_basis.html" class="internal"><span class="codenumber">3.6</span> <span class="title">Bases</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_basis.html#ss_bases" class="internal"><span class="codenumber">3.6.1</span> <span class="title">Bases of vector spaces</span></a></div></li>
<li><div class="toc-item"><a href="s_basis.html#ss_bases_transformations" class="internal"><span class="codenumber">3.6.2</span> <span class="title">Bases and linear transformations</span></a></div></li>
<li><div class="toc-item"><a href="s_basis.html#s_basis_ex" class="internal"><span class="codenumber">3.6.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_dimension.html" class="internal"><span class="codenumber">3.7</span> <span class="title">Dimension</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_dimension.html#ss_dimension" class="internal"><span class="codenumber">3.7.1</span> <span class="title">Dimension of a vector space</span></a></div></li>
<li><div class="toc-item"><a href="s_dimension.html#s_dimension_ex" class="internal"><span class="codenumber">3.7.2</span> <span class="title">Street smarts!</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_rank_nullity.html" class="internal"><span class="codenumber">3.8</span> <span class="title">Rank-nullity theorem and fundamental spaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_rank_nullity.html#ss_rank-nullity" class="internal"><span class="codenumber">3.8.1</span> <span class="title">The rank-nullity theorem</span></a></div></li>
<li><div class="toc-item"><a href="s_rank_nullity.html#ss_fundamental_spaces" class="internal"><span class="codenumber">3.8.2</span> <span class="title">Fundamental spaces of matrices</span></a></div></li>
<li><div class="toc-item"><a href="s_rank_nullity.html#ss_expand_contract" class="internal"><span class="codenumber">3.8.3</span> <span class="title">Contracting and expanding to bases</span></a></div></li>
<li><div class="toc-item"><a href="s_rank_nullity.html#s_rank_nullity_ex" class="internal"><span class="codenumber">3.8.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_isom.html" class="internal"><span class="codenumber">3.9</span> <span class="title">Isomorphisms</span></a></div>
<ul class="structural"><li><div class="toc-item"><a href="s_isom.html#ss_isomorphisms" class="internal"><span class="codenumber">3.9.1</span> <span class="title">Isomorphisms</span></a></div></li></ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="c_innerproductspaces.html" class="internal"><span class="codenumber">4</span> <span class="title">Inner product spaces</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="s_innerproducts.html" class="internal"><span class="codenumber">4.1</span> <span class="title">Inner product spaces</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_innerproducts.html#ss_inner_products" class="internal"><span class="codenumber">4.1.1</span> <span class="title">Inner products</span></a></div></li>
<li><div class="toc-item"><a href="s_innerproducts.html#ss_norm_distance" class="internal"><span class="codenumber">4.1.2</span> <span class="title">Norm and distance</span></a></div></li>
<li><div class="toc-item"><a href="s_innerproducts.html#subsection-62" class="internal"><span class="codenumber">4.1.3</span> <span class="title">Cauchy-Schwarz inequality, triangle inequalities, and angles between vectors</span></a></div></li>
<li><div class="toc-item"><a href="s_innerproducts.html#subsection-63" class="internal"><span class="codenumber">4.1.4</span> <span class="title">Choosing your inner product</span></a></div></li>
<li><div class="toc-item"><a href="s_innerproducts.html#s_innerproducts_ex" class="internal"><span class="codenumber">4.1.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_orthogonality.html" class="internal"><span class="codenumber">4.2</span> <span class="title">Orthogonal bases</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_orthogonality.html#ss_orthogonal" class="internal"><span class="codenumber">4.2.1</span> <span class="title">Orthogonal vectors and sets</span></a></div></li>
<li><div class="toc-item"><a href="s_orthogonality.html#subsection-65" class="internal"><span class="codenumber">4.2.2</span> <span class="title">Orthogonal bases</span></a></div></li>
<li><div class="toc-item"><a href="s_orthogonality.html#s_orthogonal_bases_ex" class="internal"><span class="codenumber">4.2.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li class="active">
<div class="toc-item"><a href="s_orthogonal_projection.html" class="internal"><span class="codenumber">4.3</span> <span class="title">Orthogonal projection</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_orthogonal_projection.html#ss_ortho_complement" class="internal"><span class="codenumber">4.3.1</span> <span class="title">Orthogonal complement</span></a></div></li>
<li><div class="toc-item"><a href="s_orthogonal_projection.html#subsection-67" class="internal"><span class="codenumber">4.3.2</span> <span class="title">Orthogonal Projection</span></a></div></li>
<li><div class="toc-item"><a href="s_orthogonal_projection.html#subsection-68" class="internal"><span class="codenumber">4.3.3</span> <span class="title">Orthogonal projection in <span class="process-math">\(\R^2\)</span> and <span class="process-math">\(\R^3\)</span></span></a></div></li>
<li><div class="toc-item"><a href="s_orthogonal_projection.html#subsection-69" class="internal"><span class="codenumber">4.3.4</span> <span class="title">Trigonometric polynomial approximation</span></a></div></li>
<li><div class="toc-item"><a href="s_orthogonal_projection.html#subsection-70" class="internal"><span class="codenumber">4.3.5</span> <span class="title">Least-squares solution to linear systems</span></a></div></li>
<li><div class="toc-item"><a href="s_orthogonal_projection.html#s_orthogonal_projection_ex" class="internal"><span class="codenumber">4.3.6</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="c_transbasis.html" class="internal"><span class="codenumber">5</span> <span class="title">Eigenvectors and diagonalization</span></a></div>
<ul class="structural">
<li>
<div class="toc-item"><a href="s_coordinatevectors.html" class="internal"><span class="codenumber">5.1</span> <span class="title">Coordinate vectors</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_coordinatevectors.html#ss_coordinate_vectors" class="internal"><span class="codenumber">5.1.1</span> <span class="title">Coordinate vectors</span></a></div></li>
<li><div class="toc-item"><a href="s_coordinatevectors.html#ss_coordinate_transformation" class="internal"><span class="codenumber">5.1.2</span> <span class="title">Coordinate vector transformation</span></a></div></li>
<li><div class="toc-item"><a href="s_coordinatevectors.html#s_coordinatevectors_ex" class="internal"><span class="codenumber">5.1.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_matrixreps.html" class="internal"><span class="codenumber">5.2</span> <span class="title">Matrix representations of linear transformations</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_matrixreps.html#ss_matrix_reps" class="internal"><span class="codenumber">5.2.1</span> <span class="title">Matrix representations of linear transformations</span></a></div></li>
<li><div class="toc-item"><a href="s_matrixreps.html#ss_matrixreps_models" class="internal"><span class="codenumber">5.2.2</span> <span class="title">Matrix representations as models</span></a></div></li>
<li><div class="toc-item"><a href="s_matrixreps.html#subsection-75" class="internal"><span class="codenumber">5.2.3</span> <span class="title">Choice of basis</span></a></div></li>
<li><div class="toc-item"><a href="s_matrixreps.html#s_matrixreps_ex" class="internal"><span class="codenumber">5.2.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_changeofbasis.html" class="internal"><span class="codenumber">5.3</span> <span class="title">Change of basis</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_changeofbasis.html#ss_change_of_basis" class="internal"><span class="codenumber">5.3.1</span> <span class="title">Change of basis matrix</span></a></div></li>
<li><div class="toc-item"><a href="s_changeofbasis.html#ss_changebasis_orthonormal" class="internal"><span class="codenumber">5.3.2</span> <span class="title">Working with orthonormal bases</span></a></div></li>
<li><div class="toc-item"><a href="s_changeofbasis.html#subsection-78" class="internal"><span class="codenumber">5.3.3</span> <span class="title">Change of basis for transformations</span></a></div></li>
<li><div class="toc-item"><a href="s_changeofbasis.html#ss_changebasis_similarity" class="internal"><span class="codenumber">5.3.4</span> <span class="title">Similarity and the holy commutative tent of linear algebra</span></a></div></li>
<li><div class="toc-item"><a href="s_changeofbasis.html#s_changeofbasis_ex" class="internal"><span class="codenumber">5.3.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_eigenvectors.html" class="internal"><span class="codenumber">5.4</span> <span class="title">Eigenvectors and eigenvalues</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_eigenvectors.html#subsection-80" class="internal"><span class="codenumber">5.4.1</span> <span class="title">Eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="s_eigenvectors.html#subsection-81" class="internal"><span class="codenumber">5.4.2</span> <span class="title">Finding eigenvalues and eigenvectors systematically</span></a></div></li>
<li><div class="toc-item"><a href="s_eigenvectors.html#ss_eigenvectors_characteristic_polynomial" class="internal"><span class="codenumber">5.4.3</span> <span class="title">Properties of the characteristic polynomial</span></a></div></li>
<li><div class="toc-item"><a href="s_eigenvectors.html#s_eigenvectors_ex" class="internal"><span class="codenumber">5.4.4</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_diagonalization.html" class="internal"><span class="codenumber">5.5</span> <span class="title">Diagonalization</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_diagonalization.html#ss_diagonalizable" class="internal"><span class="codenumber">5.5.1</span> <span class="title">Diagonalizable transformations</span></a></div></li>
<li><div class="toc-item"><a href="s_diagonalization.html#ss_diagonalizable_independent_eigenvectors" class="internal"><span class="codenumber">5.5.2</span> <span class="title">Linear independence of eigenvectors</span></a></div></li>
<li><div class="toc-item"><a href="s_diagonalization.html#ss_diagonalizable_matrices" class="internal"><span class="codenumber">5.5.3</span> <span class="title">Diagonalizable matrices</span></a></div></li>
<li><div class="toc-item"><a href="s_diagonalization.html#subsection-86" class="internal"><span class="codenumber">5.5.4</span> <span class="title">Algebraic and geometric multiplicity</span></a></div></li>
<li><div class="toc-item"><a href="s_diagonalization.html#s_diagonalization_ex" class="internal"><span class="codenumber">5.5.5</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
<li>
<div class="toc-item"><a href="s_spectral_theorem.html" class="internal"><span class="codenumber">5.6</span> <span class="title">The spectral theorem</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="s_spectral_theorem.html#ss_self-adjoint" class="internal"><span class="codenumber">5.6.1</span> <span class="title">Self-adjoint operators</span></a></div></li>
<li><div class="toc-item"><a href="s_spectral_theorem.html#ss_spectal_theorem_operators" class="internal"><span class="codenumber">5.6.2</span> <span class="title">The spectral theorem for self-adjoint operators</span></a></div></li>
<li><div class="toc-item"><a href="s_spectral_theorem.html#s_spectral_theorem_ex" class="internal"><span class="codenumber">5.6.3</span> <span class="title">Exercises</span></a></div></li>
</ul>
</li>
</ul>
</li>
<li>
<div class="toc-item"><a href="backmatter-1.html" class="internal"><span class="title">Back Matter</span></a></div>
<ul class="structural">
<li><div class="toc-item"><a href="appendix-notation.html" class="internal"><span class="codenumber">A</span> <span class="title">Notation</span></a></div></li>
<li><div class="toc-item"><a href="appendix-exercises.html" class="internal"><span class="codenumber">B</span> <span class="title">Exercises</span></a></div></li>
<li><div class="toc-item"><a href="appendix-defs.html" class="internal"><span class="codenumber">C</span> <span class="title">Definitions</span></a></div></li>
<li><div class="toc-item"><a href="appendix-thms.html" class="internal"><span class="codenumber">D</span> <span class="title">Theory and procedures</span></a></div></li>
<li><div class="toc-item"><a href="appendix-egs.html" class="internal"><span class="codenumber">E</span> <span class="title">Examples</span></a></div></li>
<li><div class="toc-item"><a href="appendix-sage.html" class="internal"><span class="codenumber">F</span> <span class="title">Sage examples</span></a></div></li>
<li><div class="toc-item"><a href="appendix-mantras.html" class="internal"><span class="codenumber">G</span> <span class="title">Video examples and figures</span></a></div></li>
<li><div class="toc-item"><a href="appendix-vids.html" class="internal"><span class="codenumber">H</span> <span class="title">Mantras and fiats</span></a></div></li>
<li><div class="toc-item"><a href="index-1.html" class="internal"><span class="title">Index</span></a></div></li>
</ul>
</li>
</ul></nav></div>
<main class="ptx-main"><div id="ptx-content" class="ptx-content"><section class="section" id="s_orthogonal_projection"><h2 class="heading hide-type">
<span class="type">Section</span> <span class="codenumber">4.3</span> <span class="title">Orthogonal projection</span>
</h2>
<section class="introduction" id="introduction-66"><div class="para logical" id="p-3051">
<div class="para">A trick we learn early on in physics-- specifically, in dynamics problems in <span class="process-math">\(\R^2\)</span>-- is to pick a convenient axis and then decompose any relevant vectors (force, acceleration, velocity, position, etc.) into a sum of two components: one that points along the chosen axis, and one that points perpendicularly to it. As we will see in this section, this technique can be vastly generalized. Namely, instead of <span class="process-math">\(\R^2\)</span> we  can take any inner product space <span class="process-math">\((V, \langle\, , \rangle)\text{;}\)</span> and instead of a chosen axis in <span class="process-math">\(\R^2\text{,}\)</span> we can choose any finite-dimensional subspace <span class="process-math">\(W\subseteq V\text{;}\)</span> then any <span class="process-math">\(\boldv\in V\)</span> can be decomposed in the form</div>
<div class="displaymath process-math">
\begin{equation*}
\boldv=\boldw+\boldw^\perp,
\end{equation*}
</div>
<div class="para">where <span class="process-math">\(\boldw\in W\)</span> and <span class="process-math">\(\boldw^\perp\)</span> is a vector <em class="emphasis">orthogonal</em> to <span class="process-math">\(W\text{,}\)</span> in a sense we will make precise below. Just as in our toy physics example, this manner of decomposing vectors helps simplify computations in problems where the subspace <span class="process-math">\(W\)</span> chosen is of central importance.</div>
</div></section><section class="subsection" id="ss_ortho_complement"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.1</span> <span class="title">Orthogonal complement</span>
</h3>
<section class="introduction" id="introduction-67"><div class="para" id="p-3052">We begin by making sense of what it means for a vector to be orthogonal to a subspace.</div></section><article class="definition definition-like" id="d_orthogonal_complement"><h4 class="heading">
<span class="type">Definition</span><span class="space"> </span><span class="codenumber">4.3.1</span><span class="period">.</span><span class="space"> </span><span class="title">Orthogonal complement.</span>
</h4>  <div class="para" id="p-3053">. Let <span class="process-math">\((V,\langle \ , \rangle)\)</span> be an inner product vector space, and let <span class="process-math">\(W\subseteq V\)</span> be a subspace.</div> <div class="para" id="p-3054">A vector <span class="process-math">\(\boldv\)</span> is <dfn class="terminology">orthogonal</dfn> to <span class="process-math">\(W\)</span> if it is orthogonal to every element of <span class="process-math">\(W\text{:}\)</span>i.e., if <span class="process-math">\(\langle \boldv, \boldw\rangle=0\)</span> for all <span class="process-math">\(\boldw\in W\text{.}\)</span>
</div> <div class="para logical" id="p-3055">
<div class="para">The <dfn class="terminology">orthogonal complement</dfn> of <span class="process-math">\(W\text{,}\)</span> denoted <span class="process-math">\(W^\perp\text{,}\)</span> is the set of all elements of <span class="process-math">\(V\)</span> orthogonal to <span class="process-math">\(W\text{:}\)</span> i.e.,</div>
<div class="displaymath process-math">
\begin{equation*}
W^\perp=\{\boldv\in V\colon \langle \boldv, \boldw\rangle=0 \text{ for all } \boldw\in W\}\text{.}
\end{equation*}
</div>
</div></article><article class="remark remark-like" id="rm_computing_ortho_comp"><h4 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">4.3.2</span><span class="period">.</span><span class="space"> </span><span class="title">Computing <span class="process-math">\(W^\perp\)</span>.</span>
</h4> <div class="para logical" id="p-3056">
<div class="para">According to <a href="" class="xref" data-knowl="./knowl/d_orthogonal_complement.html" title="Definition 4.3.1: Orthogonal complement">Definition¬†4.3.1</a>, to verify that a vector <span class="process-math">\(\boldv\)</span> lies in <span class="process-math">\(W^\perp\text{,}\)</span> we must show that <span class="process-math">\(\langle \boldv, \boldw\rangle=0\)</span> for all <span class="process-math">\(\boldw\in W\text{.}\)</span> The ‚Äúfor all‚Äù quantifier here can potentially make this an onerous task: there are in principle infinitely many <span class="process-math">\(\boldw\)</span> to check! In the special case where <span class="process-math">\(W\)</span> has a finite spanning set, so that <span class="process-math">\(W=\Span \{\boldw_1, \boldw_2,\dots, \boldw_r\}\)</span> for some vectors <span class="process-math">\(\boldw_i\text{,}\)</span> deciding whether <span class="process-math">\(\boldv\in W^\perp\)</span> reduces to checking whether <span class="process-math">\(\langle \boldv, \boldw_i\rangle=0\)</span> for all <span class="process-math">\(1\leq i\leq r\text{.}\)</span> In other words, we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/d_orthogonal_complement.html ./knowl/ex_ortho_comp.html">
\begin{equation*}
\boldv\in W^\perp\iff \langle \boldv, \boldw_i\rangle=0 \text{ for all } 1\leq i\leq r\text{.}
\end{equation*}
</div>
<div class="para">The forward implication of this equivalence is clear: if <span class="process-math">\(\boldv\)</span> is orthogonal to all elements of <span class="process-math">\(W\text{,}\)</span> then clearly it is orthogonal to each <span class="process-math">\(\boldw_i\text{.}\)</span> The reverse implication is left as an exercise. (See <a href="" class="xref" data-knowl="./knowl/ex_ortho_comp.html" title="Exercise 4.3.6.7">Exercise¬†4.3.6.7</a>.)</div>
</div> <div class="para" id="p-3057">We illustrate this computational technique in the next examples.</div></article><article class="example example-like" id="eg_ortho_comp_line"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.3</span><span class="period">.</span>
</h4>
<div class="para" id="p-3058">Consider the inner product space <span class="process-math">\(\R^2\)</span> together with the dot product. Let <span class="process-math">\(W=\Span\{(1,1)\}=\{(t,t)\colon t\in \R\}\text{:}\)</span> the line <span class="process-math">\(\ell\subseteq \R^2\)</span> with equation <span class="process-math">\(y=x\text{.}\)</span> Compute <span class="process-math">\(W^\perp\)</span> and identify it as a familiar geometric object in <span class="process-math">\(\R^2\text{.}\)</span>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-93" id="solution-93"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-93"><div class="solution solution-like"><div class="para logical" id="p-3059">
<div class="para">According to <a href="" class="xref" data-knowl="./knowl/rm_computing_ortho_comp.html" title="Remark 4.3.2: Computing W^\perp">Remark¬†4.3.2</a>, since <span class="process-math">\(W=\Span\{(1,1)\}\text{,}\)</span> we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/rm_computing_ortho_comp.html">
\begin{equation*}
\boldx\in W^\perp \iff \boldx\cdot (1,1)=0\text{.}
\end{equation*}
</div>
<div class="para">Letting <span class="process-math">\(\boldx=(x,y)\text{,}\)</span> we see that <span class="process-math">\(\boldx\cdot (1,1)=0\)</span> if and only if <span class="process-math">\(x+y=0\text{,}\)</span> if and only if <span class="process-math">\(y=-x\text{.}\)</span> Thus <span class="process-math">\(W^\perp=\{(x,y)\colon y=-x\}\)</span> is the line <span class="process-math">\(\ell'\subseteq \R^2\)</span> with equation <span class="process-math">\(y=-x\text{.}\)</span> Observe that the lines <span class="process-math">\(\ell\)</span> and <span class="process-math">\(\ell'\)</span> are indeed perpendicular to one another. (Graph them!)</div>
</div></div></div>
</div></article><article class="example example-like" id="eg_ortho_comp_plane"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.4</span><span class="period">.</span>
</h4>
<div class="para" id="p-3060">Consider the inner product space <span class="process-math">\(\R^3\)</span> together with the dot product. Let <span class="process-math">\(W\subseteq \R^3\)</span> be the plane with equation <span class="process-math">\(x-2y-z=0\text{.}\)</span>  Compute <span class="process-math">\(W^\perp\)</span> and identify this as a familiar geometric object in <span class="process-math">\(\R^3\text{.}\)</span>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-94" id="solution-94"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-94"><div class="solution solution-like"><div class="para logical" id="p-3061">
<div class="para">First, solving <span class="process-math">\(x-2y-z=0\)</span> for <span class="process-math">\((x,y,z)\text{,}\)</span> we see that</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/rm_computing_ortho_comp.html">
\begin{equation*}
W=\{(2s+t,s,t)\colon s,t\in \R\}=\Span\{(2,1,0),(1,0,1)\}\text{.}
\end{equation*}
</div>
<div class="para">Next, according to <a href="" class="xref" data-knowl="./knowl/rm_computing_ortho_comp.html" title="Remark 4.3.2: Computing W^\perp">Remark¬†4.3.2</a> we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/rm_computing_ortho_comp.html">
\begin{equation*}
\boldx\in W^\perp\iff \boldx\cdot (2,1,0)=0 \text{ and } \boldx\cdot (1,0,1)=0\text{.}
\end{equation*}
</div>
<div class="para">It follows that <span class="process-math">\(W^\perp\)</span> is the set of vectors <span class="process-math">\(\boldx=(x,y,z)\)</span> satisfying the linear system</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/rm_computing_ortho_comp.html">
\begin{equation*}
\begin{linsys}{3}
2x\amp +\amp y \amp \amp  \amp = \amp 0\\
x\amp \amp  \amp +\amp z \amp = \amp 0
\end{linsys}.
\end{equation*}
</div>
<div class="para">Solving this system using Gaussian elimination we conclude that</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/rm_computing_ortho_comp.html">
\begin{equation*}
W^\perp=\{(t,-2t,-t)\colon t\in \R\}=\Span\{(1,-2,-1)\}\text{,}
\end{equation*}
</div>
<div class="para">which we recognize as the line <span class="process-math">\(\ell\subseteq \R^3\)</span> passing through the origin with direction vector <span class="process-math">\((1,-2,-1)\text{.}\)</span> This is none other than the normal line to the plane <span class="process-math">\(W\)</span> passing through the origin.</div>
</div></div></div>
</div></article><article class="theorem theorem-like" id="th_orthogonal_complement"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.3.5</span><span class="period">.</span><span class="space"> </span><span class="title">Orthogonal complement.</span>
</h4>
<div class="para logical" id="p-3062">
<div class="para">Let <span class="process-math">\((V,\langle \ , \rangle)\)</span> be an inner product vector space, and let <span class="process-math">\(W\subseteq V\)</span> be a subspace.</div>
<ol class="decimal">
<li id="li-902"><div class="para" id="p-3063">The orthogonal complement <span class="process-math">\(W^\perp\)</span> is a subspace of <span class="process-math">\(V\text{.}\)</span>
</div></li>
<li id="li-903"><div class="para" id="p-3064">We have <span class="process-math">\(W\cap W^\perp=\{\boldzero\}\text{.}\)</span>
</div></li>
<li id="li-904"><div class="para logical" id="p-3065">
<div class="para">If <span class="process-math">\(\dim V=n\lt \infty\)</span> then</div>
<div class="displaymath process-math">
\begin{equation*}
\dim W+\dim W^\perp=n\text{.}
\end{equation*}
</div>
</div></li>
</ol>
</div></article><article class="hiddenproof" id="proof-79"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-79"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-79"><article class="hiddenproof"><div class="para" id="p-3066">The proof is left as an exercise. (See <a href="" class="xref" data-knowl="./knowl/ex_orthocomp_subspace.html" title="Exercise 4.3.6.9">Exercise¬†4.3.6.9‚Äì4.3.6.10</a>.)</div></article></div>
<article class="example example-like" id="example-91"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.6</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-3067">
<div class="para">Consider the inner product space <span class="process-math">\(\R^3\)</span> with the dot product. Let <span class="process-math">\(W=\Span\{(1,1,1)\}\subset \R^3\text{,}\)</span> the line passing through the origin with direction vector <span class="process-math">\((1,1,1)\text{.}\)</span> The orthogonal complement <span class="process-math">\(W^\perp\)</span> is the set of vectors orthogonal to <span class="process-math">\((1,1,1)\text{.}\)</span> Using the definition of dot product, this is the set of solutions <span class="process-math">\((x,y,z)\)</span> to the equation</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_orthogonal_complement.html">
\begin{equation*}
x+y+z=0\text{,}
\end{equation*}
</div>
<div class="para">which we recognize as the plane passing through the origin with normal vector <span class="process-math">\((1,1,1)\text{.}\)</span> Note that we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_orthogonal_complement.html">
\begin{equation*}
\dim W+\dim W^\perp=1+2=3,
\end{equation*}
</div>
<div class="para">as predicted in <a href="" class="xref" data-knowl="./knowl/th_orthogonal_complement.html" title="Theorem 4.3.5: Orthogonal complement">Theorem¬†4.3.5</a>.</div>
</div></article><div class="para" id="p-3068">The notion of orthogonal complement gives us a more conceptual way of understanding the relationship between the various fundamental spaces of a matrix.</div>
<article class="theorem theorem-like" id="th_row_null_comp"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.3.7</span><span class="period">.</span><span class="space"> </span><span class="title">Fundamental spaces and orthogonal complements.</span>
</h4>
<div class="para logical" id="p-3069">
<div class="para">Let <span class="process-math">\(A\)</span> be <span class="process-math">\(m\times n\text{,}\)</span> and consider <span class="process-math">\(\R^n\)</span> and <span class="process-math">\(\R^m\)</span> as inner product spaces with respect to the dot product. Then:</div>
<ol class="decimal">
<li id="li-905"><div class="para" id="p-3070">
<span class="process-math">\(\NS(A)=\left(\RS(A)\right)^\perp\text{,}\)</span> and thus <span class="process-math">\(\RS(A)=\left(\NS(A)\right)^\perp\text{.}\)</span>
</div></li>
<li id="li-906"><div class="para" id="p-3071">
<span class="process-math">\(\NS(A^T)=\left(\CS(A)\right)^\perp\text{,}\)</span> and thus <span class="process-math">\(\CS(A)=\left(\NS(A^T)\right)^\perp\text{.}\)</span>
</div></li>
</ol>
</div></article><article class="hiddenproof" id="proof-80"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-80"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-80"><article class="hiddenproof"><ol class="decimal">
<li id="li-907">
<div class="para" id="p-3072">Using the dot product method of matrix multiplication, we see that a vector <span class="process-math">\(\boldx\in\NS(A)\)</span> if and only if <span class="process-math">\(\boldx\cdot\boldr_i=0\)</span> for each row <span class="process-math">\(\boldr_i\)</span> of <span class="process-math">\(A\text{,}\)</span> if and only if <span class="process-math">\(\boldx\cdot \boldw=0\)</span> for all <span class="process-math">\(\boldw\in \Span \{\boldr_1, \boldr_2, \dots, \boldr_m\}=\RS A\)</span> (see <a href="" class="xref" data-knowl="./knowl/rm_computing_ortho_comp.html" title="Remark 4.3.2: Computing W^\perp">Remark¬†4.3.2</a>), if and only if <span class="process-math">\(\boldx\in (\RS A)^\perp\text{.}\)</span> This shows <span class="process-math">\(\NS A=(\RS A)^\perp\text{.}\)</span>
</div>
<div class="para" id="p-3073">We can use <a href="" class="xref" data-knowl="./knowl/cor_orthocomp_selfdual.html" title="Corollary 4.3.13">Corollary¬†4.3.13</a> to conclude <span class="process-math">\(\RS A=(\NS A)^\perp\text{.}\)</span> Alternatively, and more directly, the argument above shows that <span class="process-math">\(\boldw\in \RS A\implies \boldw\in (\NS A)^\perp\text{,}\)</span> proving <span class="process-math">\(\RS A\subseteq (\NS A)^\perp\text{.}\)</span> Next, by the rank-nullity theorem we have <span class="process-math">\(\dim \RS A=n-\dim\NS A\text{;}\)</span> and by <a href="" class="xref" data-knowl="./knowl/th_orthogonal_complement.html" title="Theorem 4.3.5: Orthogonal complement">Theorem¬†4.3.5</a> we have <span class="process-math">\(\dim (\NS A)^\perp=n-\dim\NS A\text{.}\)</span> It follows that <span class="process-math">\(\dim\RS A=\dim (\NS A)^\perp\text{.}\)</span> Since <span class="process-math">\(\RS A\subseteq (\NS A)^\perp\)</span> and <span class="process-math">\(\dim \RS A=\dim (\NS A)^\perp\text{,}\)</span> we conclude by <a href="" class="xref" data-knowl="./knowl/cor_dimension_subspace.html" title="Corollary 3.7.10: Dimension of subspaces">Corollary¬†3.7.10</a> that <span class="process-math">\(\RS A=(\NS A)^\perp\text{.}\)</span>
</div>
</li>
<li id="li-908"><div class="para" id="p-3074">This follows from (1) and the fact that <span class="process-math">\(\CS(A)=\RS(A^T)\text{.}\)</span>
</div></li>
</ol></article></div>
<article class="example example-like" id="example-92"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.8</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-3075">
<div class="para">Understanding the orthogonal relationship between <span class="process-math">\(\NS A \)</span> and <span class="process-math">\(\RS A\)</span> allows us in many cases to quickly determine/visualize the one from the other. As an example, consider <span class="process-math">\(A=\begin{bmatrix}1\amp -1\amp 1\\ 1\amp -1\amp -1 \end{bmatrix}\text{.}\)</span> Looking at the columns, we see easily that <span class="process-math">\(\rank A =2\text{,}\)</span> which implies that <span class="process-math">\(\nullity A=3-2=1\text{.}\)</span> Since <span class="process-math">\((1,-1,0)\)</span> is an element of <span class="process-math">\(\NS(A)\)</span> and <span class="process-math">\(\dim\NS A=1\text{,}\)</span> we must have <span class="process-math">\(\NS A=\Span\{(1,-1,0)\}\text{,}\)</span> a line. By orthogonality, we conclude that</div>
<div class="displaymath process-math">
\begin{equation*}
\RS A=(\NS A)^\perp\text{,}
\end{equation*}
</div>
<div class="para">which is the plane with normal vector <span class="process-math">\((1,-1,0)\)</span> passing through the origin.</div>
</div></article></section><section class="subsection" id="subsection-67"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.2</span> <span class="title">Orthogonal Projection</span>
</h3>
<article class="theorem theorem-like" id="th_orthogonal_projection"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.3.9</span><span class="period">.</span><span class="space"> </span><span class="title">Orthogonal projection theorem.</span>
</h4>
<div class="para" id="p-3076">Let <span class="process-math">\((V,\langle \ , \rangle)\)</span> be an inner product space, and let <span class="process-math">\(W\subseteq V\)</span> be a finite-dimensional subspace.</div> <ol class="decimal">
<li id="li-909">
<span class="heading"><span class="title">Orthogonal decomposition.</span></span><div class="para logical" id="p-3077">
<div class="para">For all <span class="process-math">\(\boldv\in V\)</span> there are vectors <span class="process-math">\(\boldw\)</span> and <span class="process-math">\(\boldw^\perp\)</span> satisfying</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_decomp.html" id="eq_ortho_decomp">
\begin{equation}
\boldv=\boldw+\boldw^\perp, \boldw\in W, \boldw^\perp\in W^\perp\text{.}\tag{4.3.1}
\end{equation}
</div>
<div class="para">Furthermore, the pair <span class="process-math">\(\boldw, \boldw^\perp\)</span> is unique in the following sense: if we have <span class="process-math">\(\boldv=\boldu+\boldu^\perp\)</span> for some <span class="process-math">\(\boldu\in W\)</span> and <span class="process-math">\(\boldu^\perp\in W^\perp\text{,}\)</span> then <span class="process-math">\(\boldu=\boldw\)</span> and <span class="process-math">\(\boldu^\perp=\boldw^\perp\text{.}\)</span> Accordingly, the vector equation <a href="" class="xref" data-knowl="./knowl/eq_ortho_decomp.html" title="Equation 4.3.1">(4.3.1)</a> is called the <dfn class="terminology">orthogonal decomposition</dfn> of <span class="process-math">\(\boldv\)</span> with respect to <span class="process-math">\(W\text{;}\)</span> and the vector <span class="process-math">\(\boldw\)</span> is called the <dfn class="terminology">orthogonal projection</dfn> of <span class="process-math">\(\boldv\)</span> onto <span class="process-math">\(W\text{,}\)</span> denoted <span class="process-math">\(\boldw=\proj{\boldv}{W}\text{.}\)</span>
</div>
</div>
</li>
<li id="li-910">
<span class="heading"><span class="title">Orthogonal projection formula.</span></span><div class="para logical" id="p-3078">
<div class="para">Choose any orthogonal basis <span class="process-math">\(B=\{\boldw_1, \boldw_2, \dots, \boldw_r\}\)</span> of <span class="process-math">\(W\text{.}\)</span> We have</div>
<div class="displaymath process-math" id="eq_ortho_proj_formula">
\begin{equation}
\proj{\boldv}{W}=\sum_{i=1}^r\frac{\angvec{\boldv,\boldw_i}}{\angvec{\boldw_i, \boldw_i}}\boldw_i\text{.}\tag{4.3.2}
\end{equation}
</div>
</div>
</li>
<li id="li-911">
<span class="heading"><span class="title">Distance to <span class="process-math">\(W\)</span>.</span></span><div class="para logical" id="p-3079">
<div class="para">The orthogonal projection <span class="process-math">\(\boldw=\proj{\boldv}{W}\)</span> is the element of <span class="process-math">\(W\)</span> that is closest to <span class="process-math">\(\boldv\)</span> in the following sense: for all <span class="process-math">\(\boldw'\in W\)</span> we have</div>
<div class="displaymath process-math">
\begin{equation*}
d(\boldv, \proj{\boldv}{W})\leq d(\boldv, \boldw')\text{,}
\end{equation*}
</div>
<div class="para">or equivalently,</div>
<div class="displaymath process-math" id="eq_ortho_proj_distance">
\begin{equation}
\norm{\boldv-\proj{\boldv}{W}}\leq\norm{\boldv-\boldw'}\text{.}\tag{4.3.3}
\end{equation}
</div>
<div class="para">Accordingly, we define the <dfn class="terminology">distance</dfn> <span class="process-math">\(d(\boldv, W)\)</span> between <span class="process-math">\(\boldv\)</span> and <span class="process-math">\(W\)</span> to be</div>
<div class="displaymath process-math">
\begin{equation*}
d(\boldv, W)=d(\boldv, \proj{\boldv}{W})=\norm{\boldv-\proj{\boldv}{W}}\text{.}
\end{equation*}
</div>
</div>
</li>
</ol></article><article class="hiddenproof" id="proof-81"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-81"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-81"><article class="hiddenproof"><div class="para logical" id="p-3080">
<div class="para">Let <span class="process-math">\(B=\{\boldw_1, \boldw_2, \dots, \boldw_r\}\text{.}\)</span> We first show that the vectors</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_decomp.html ./knowl/eq_ortho_proj_formula_proof.html" id="eq_ortho_proj_formula_proof">
\begin{equation}
\boldw=\sum_{i=1}^r\frac{\angvec{\boldv,\boldw_i}}{\angvec{\boldw_i, \boldw_i}}\boldw_i\tag{4.3.4}
\end{equation}
</div>
<div class="para">and <span class="process-math">\(\boldw^\perp=\boldv-\boldw\)</span> satisfy the conditions in <a href="" class="xref" data-knowl="./knowl/eq_ortho_decomp.html" title="Equation 4.3.1">(4.3.1)</a>. It is clear that the <span class="process-math">\(\boldw\)</span> defined in <a href="" class="xref" data-knowl="./knowl/eq_ortho_proj_formula_proof.html" title="Equation 4.3.4">(4.3.4)</a> is an element of <span class="process-math">\(W\text{,}\)</span> since it is a linear combination of the <span class="process-math">\(\boldw_i\text{.}\)</span> Furthermore, we see easily that our choice <span class="process-math">\(\boldw^\perp=\boldv-\boldw\)</span> satisfies</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_decomp.html ./knowl/eq_ortho_proj_formula_proof.html">
\begin{equation*}
\boldw+\boldw^\perp=\boldw+(\boldv-\boldw)=\boldv\text{.}
\end{equation*}
</div>
<div class="para">It remains only to show that <span class="process-math">\(\boldw^\perp=\boldv-\boldw\in W^\perp\text{.}\)</span> Since <span class="process-math">\(B\)</span> is a basis of <span class="process-math">\(W\text{,}\)</span> it suffices to show that <span class="process-math">\(\langle \boldw^\perp,\boldw_j\rangle=0\)</span> for all <span class="process-math">\(1\leq i\leq r\text{.}\)</span> We compute:</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_decomp.html ./knowl/eq_ortho_proj_formula_proof.html" id="md-204">
\begin{align*}
\langle \boldw^\perp, \boldw_j \rangle\amp = \langle \boldv-\proj{\boldv}{W}, \boldw_i \rangle\\
\amp =
\left\langle \boldv-\sum_{i=1}^r\frac{\angvec{\boldv,\boldw_i}}{\angvec{\boldw_i, \boldw_i}}\boldw_i, \boldw_j\right\rangle \\
\amp =
\langle \boldv, \boldw_j\rangle -\sum_{i=1}^r\frac{\angvec{\boldv,\boldw_i}}{\angvec{\boldw_i, \boldw_i}}\langle \boldw_i, \boldw_j\rangle \\
\amp =
\langle \boldv, \boldw_j\rangle -\frac{\langle \boldv, \boldw_j\rangle}{\cancel{\langle \boldw_j, \boldw_j\rangle}}\cancel{\langle \boldw_j, \boldw_j\rangle}\\
\amp = 0 \text{,}
\end{align*}
</div>
<div class="para">as desired.</div>
</div> <div class="para logical" id="p-3081">
<div class="para">Having shown that a decomposition of <span class="process-math">\(\boldv\)</span> of the form <a href="" class="xref" data-knowl="./knowl/eq_ortho_decomp.html" title="Equation 4.3.1">(4.3.1)</a> exists, we now show it is unique in the sense specified. Suppose we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_decomp.html ./knowl/th_orthogonal_complement.html">
\begin{equation*}
\boldv=\boldw+\boldw^\perp=\boldu+\boldu^\perp\text{,}
\end{equation*}
</div>
<div class="para">where <span class="process-math">\(\boldw, \boldu\in W\)</span> and <span class="process-math">\(\boldw^\perp, \boldu^\perp\in W^\perp\text{.}\)</span> Rearranging, we see that</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_decomp.html ./knowl/th_orthogonal_complement.html">
\begin{equation*}
\boldw-\boldu=\boldu^\perp-\boldw^\perp\text{.}
\end{equation*}
</div>
<div class="para">We now claim that <span class="process-math">\(\boldw-\boldu=\boldu^\perp-\boldw^\perp=\boldzero\text{,}\)</span> in which case <span class="process-math">\(\boldw=\boldu\)</span> and <span class="process-math">\(\boldw^\perp=\boldu^\perp\text{,}\)</span> as desired. To see why the claim is true, consider the vector <span class="process-math">\(\boldv'=\boldw-\boldu=\boldu^\perp-\boldw^\perp\text{.}\)</span> Since <span class="process-math">\(\boldv'=\boldw-\boldu\text{,}\)</span> and <span class="process-math">\(\boldw, \boldu\in W\text{,}\)</span> we have <span class="process-math">\(\boldv'\in W\text{.}\)</span> On the other hand, since <span class="process-math">\(\boldv'=\boldu^\perp-\boldw^\perp\text{,}\)</span> and <span class="process-math">\(\boldu^\perp, \boldw^\perp\in W^\perp\text{,}\)</span> we have <span class="process-math">\(\boldv'\in W^\perp\text{.}\)</span> Thus <span class="process-math">\(\boldv'\in W\cap W^\perp\text{.}\)</span> Since <span class="process-math">\(W\cap W^\perp=\{\boldzero\}\)</span> (<a href="" class="xref" data-knowl="./knowl/th_orthogonal_complement.html" title="Theorem 4.3.5: Orthogonal complement">Theorem¬†4.3.5</a>), we conclude <span class="process-math">\(\boldv'=\boldw-\boldu=\boldu^\perp-\boldw^\perp=\boldzero\text{,}\)</span> as claimed.</div>
</div> <div class="para logical" id="p-3082">
<div class="para">At this point we have proved both (1) and (2), and it remains only to show that <a href="" class="xref" data-knowl="./knowl/eq_ortho_proj_distance.html" title="Equation 4.3.3">(4.3.3)</a> holds for all <span class="process-math">\(\boldw'\in W\text{.}\)</span> To this end we compute:</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_proj_distance.html ./knowl/ex_ortho_pythag.html" id="md-205">
\begin{align*}
\norm{\boldv-\boldw'}^2\amp = \norm{\boldw^\perp+(\boldw-\boldw')}^2\\
\amp =\norm{\boldw^\perp}^2+\norm{\boldw-\boldw'}^2 \amp (\knowl{./knowl/ex_ortho_pythag.html}{\text{Exercise 4.2.3.13}})\\
\amp \geq \norm{\boldw^\perp}^2\\
\amp =\norm{\boldv-\boldw}^2\text{.}
\end{align*}
</div>
<div class="para">This shows <span class="process-math">\(\norm{\boldv-\boldw'}^2\geq \norm{\boldv-\boldw}^2\text{.}\)</span> Taking square-roots now proves the desired inequality.</div>
</div></article></div>
<article class="remark remark-like" id="rm_ortho_proj_formula"><h4 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">4.3.10</span><span class="period">.</span><span class="space"> </span><span class="title">Orthogonal projection formula.</span>
</h4> <div class="para" id="p-3083">The formula <a href="" class="xref" data-knowl="./knowl/eq_ortho_proj_formula.html" title="Equation 4.3.2">(4.3.2)</a> is very convenient for computing an orthogonal projection <span class="process-math">\(\proj{\boldv}{W}\text{,}\)</span> but mark well this important detail: to apply the formula we must first provide an <em class="emphasis">orthogonal</em> basis of <span class="process-math">\(W\text{.}\)</span> Thus unless one is provided, our first step in an orthogonal projection computation is to produce an orthogonal basis of <span class="process-math">\(W\text{.}\)</span> In some simple cases (e.g., when <span class="process-math">\(W\)</span> is 1- or 2-dimensional) this can be done by inspection. Otherwise, we use the Gram-Schmidt procedure.</div></article><article class="example example-like" id="example-93"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.11</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-3084">
<div class="para">Consider the inner product space <span class="process-math">\(\R^3\)</span> with the dot product. Let <span class="process-math">\(W\subseteq\R^3\)</span> be the plane with equation <span class="process-math">\(x+y+z=0\text{.}\)</span> Compute <span class="process-math">\(\proj{\boldv}{W}\)</span> for each <span class="process-math">\(\boldv\)</span> below.</div>
<ol class="decimal">
<li id="li-912"><div class="para" id="p-3085"><span class="process-math">\(\displaystyle \boldv=(3,-2,2)\)</span></div></li>
<li id="li-913"><div class="para" id="p-3086"><span class="process-math">\(\displaystyle \boldv=(2,1,-3)\)</span></div></li>
<li id="li-914"><div class="para" id="p-3087"><span class="process-math">\(\displaystyle \boldv=(-7,-7,-7)\)</span></div></li>
</ol>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-95" id="solution-95"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-95"><div class="solution solution-like"><div class="para logical" id="p-3088">
<div class="para">According to <a href="" class="xref" data-knowl="./knowl/rm_ortho_proj_formula.html" title="Remark 4.3.10: Orthogonal projection formula">Remark¬†4.3.10</a> our first step is to produce an orthogonal basis of <span class="process-math">\(W\text{.}\)</span> We do so by inspection. Since <span class="process-math">\(\dim W=2\text{,}\)</span> we simply need to find two solutions to <span class="process-math">\(x+y+z=0\)</span> that are orthogonal to one another: e.g., <span class="process-math">\(\boldw_1=(1,-1,0)\)</span> and <span class="process-math">\(\boldw_2=(1,1,-2)\text{.}\)</span> Thus we choose <span class="process-math">\(B=\{ (1,-1,0), (1,1,-2)\}\)</span> as our orthogonal basis, and our computations become a matter of applying <a href="" class="xref" data-knowl="./knowl/eq_ortho_proj_formula.html" title="Equation 4.3.2">(4.3.2)</a>, which in this case becomes</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/rm_ortho_proj_formula.html ./knowl/eq_ortho_proj_formula.html ./knowl/ex_orthoproj_props.html">
\begin{equation*}
\proj{\boldv}{W}=\frac{\boldv\cdot\boldw_1}{\boldw_1\cdot \boldw_1}\boldw_1+\frac{\boldv\cdot\boldw_2}{\boldw_2\cdot \boldw_2}\boldw_2=
\frac{\boldv\cdot\boldw_1}{2}\boldw_1+\frac{\boldv\cdot\boldw_2}{6}\boldw_2\text{.}
\end{equation*}
</div>
<div class="para">Now compute:</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/rm_ortho_proj_formula.html ./knowl/eq_ortho_proj_formula.html ./knowl/ex_orthoproj_props.html" id="md-206">
\begin{align*}
\proj{(3,-2,2)}{W} \amp =\frac{5}{2}(1,-1,0)+\frac{-3}{6}(1,1,-2)=(2,-3,1)\\
\proj{(2,1,-3)}{W} \amp =\frac{1}{2}(1,-1,0)+\frac{9}{6}(1,1,-2)=(2,1,-3)\\
\proj{(-7,-7,-7)}{W} \amp =\frac{0}{2}(1,-1,0)+\frac{0}{6}(1,1,-2)=(0,0,0)\text{.}
\end{align*}
</div>
<div class="para">The last two computations might give you pause. Why do we have <span class="process-math">\(\proj{(2,1,-3)}{W}=(2,1,-3)\)</span> and <span class="process-math">\(\proj{(-7,7-7,-7)}{W}=(0,0,0)\text{?}\)</span> The answer is that <span class="process-math">\((2,1,-3)\)</span> is already an element of <span class="process-math">\(W\text{,}\)</span> so it stands to reason that its projection is itself; and <span class="process-math">\((-7,-7,-7)\)</span> is already orthogonal to <span class="process-math">\(W\)</span> (it is a scalar multiple of <span class="process-math">\((1,1,1)\)</span>), so it stands to reason that its projection is equal to <span class="process-math">\(\boldzero\text{.}\)</span> See <a href="" class="xref" data-knowl="./knowl/ex_orthoproj_props.html" title="Exercise 4.3.6.12">Exercise¬†4.3.6.12</a> for a rigorous proof of these claims.</div>
</div></div></div>
</div></article><section class="paragraphs" id="ss_vid_eg_orthoproj_functions"><h4 class="heading"><span class="title">Video example: orthogonal projection in function space.</span></h4> <figure class="figure figure-like" id="fig_vid_orthoproj_functions"><div class="video-box" style="width: 100%;padding-top: 56.25%; margin-left: 0%; margin-right: 0%;"><iframe id="vid_orthoproj_functions" class="video" allowfullscreen="" src="https://www.youtube-nocookie.com/embed/xWuzNdExSEk?&amp;modestbranding=1&amp;rel=0"></iframe></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">4.3.12<span class="period">.</span></span><span class="space"> </span>Video: orthogonal projection in function space</figcaption></figure></section><article class="corollary theorem-like" id="cor_orthocomp_selfdual"><h4 class="heading">
<span class="type">Corollary</span><span class="space"> </span><span class="codenumber">4.3.13</span><span class="period">.</span>
</h4>
<div class="para" id="p-3089">Let <span class="process-math">\((V,\angvec{\ , \ })\)</span> be an inner product space, and let <span class="process-math">\(W\subseteq V\)</span> be a finite-dimensional subspace. Then <span class="process-math">\((W^\perp)^\perp=W\text{.}\)</span>
</div></article><article class="hiddenproof" id="proof-82"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-82"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-82"><article class="hiddenproof"><div class="para" id="p-3090">Clearly <span class="process-math">\(W\subseteq (W^\perp)^\perp\text{.}\)</span> For the other direction, take <span class="process-math">\(\boldv\in (W^\perp)^\perp\text{.}\)</span> Using the <em class="emphasis">orthogonal projection theorem</em>, we can write <span class="process-math">\(\boldv=\boldw+\boldw^\perp\)</span> with <span class="process-math">\(\boldw\in W\)</span> and <span class="process-math">\(\boldw^\perp\in W^\perp\text{.}\)</span> We will show <span class="process-math">\(\boldw^\perp=\boldzero\text{.}\)</span>
</div> <div class="para logical" id="p-3091">
<div class="para">Since <span class="process-math">\(\boldv\in (W^\perp)^\perp\)</span> we have <span class="process-math">\(\angvec{\boldv,\boldw^\perp}=0\text{.}\)</span> Then we have</div>
<div class="displaymath process-math" id="md-207">
\begin{align*}
0\amp =\angvec{\boldv,\boldw^\perp}\\
\amp =\angvec{\boldw+\boldw^\perp,\boldw^\perp}\\
\amp =\angvec{\boldw,\boldw^\perp}+\angvec{\boldw^\perp,\boldw^\perp} \amp \text{ (since \(W\perp W^\perp\)) }\\
\amp =0+\angvec{\boldw^\perp,\boldw^\perp}
\end{align*}
</div>
</div> <div class="para" id="p-3092">Thus <span class="process-math">\(\angvec{\boldw^\perp,\boldw^\perp}=0\text{.}\)</span> It follows that <span class="process-math">\(\boldw^\perp=\boldzero\text{,}\)</span> and hence <span class="process-math">\(\boldv=\boldw+\boldzero=\boldw\in W\text{.}\)</span>
</div></article></div>
<article class="corollary theorem-like" id="cor_orthoproj_linear"><h4 class="heading">
<span class="type">Corollary</span><span class="space"> </span><span class="codenumber">4.3.14</span><span class="period">.</span><span class="space"> </span><span class="title">Orthgonal projection is linear.</span>
</h4>
<div class="para" id="p-3093">Let <span class="process-math">\((V,\angvec{\ , \ })\)</span> be an inner product space, and let <span class="process-math">\(W\subseteq V\)</span> be a finite-dimensional subspace.</div> <ol class="decimal">
<li id="li-915"><div class="para logical" id="p-3094">
<div class="para">The function</div>
<div class="displaymath process-math" id="md-208">
\begin{align*}
\operatorname{proj}_W\colon V \amp\rightarrow V\\
\boldv \amp\mapsto \proj{\boldv}{W} 
\end{align*}
</div>
<div class="para">is a linear transformation.</div>
</div></li>
<li id="li-916"><div class="para" id="p-3095">We have <span class="process-math">\(\im \operatorname{proj}_W=W\)</span> and <span class="process-math">\(\NS \operatorname{proj}_W=W^\perp\text{.}\)</span>
</div></li>
</ol></article><article class="hiddenproof" id="proof-83"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-83"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-83"><article class="hiddenproof"><ol class="decimal">
<li id="li-917"><div class="para logical" id="p-3096">
<div class="para">We must show that <span class="process-math">\(\proj{c\boldv+d\boldw}{W}=c\,\proj{\boldv}{W}+d\,\proj{\boldw}{W}\)</span> for all <span class="process-math">\(c,d\in\R\)</span> and <span class="process-math">\(\boldv,\boldw\in V\text{.}\)</span> We pick an orthogonal basis <span class="process-math">\(B=\{\boldv_1,\boldv_2, \dots, \boldv_r\}\)</span> of <span class="process-math">\(W\)</span> and compute, using formula <a href="" class="xref" data-knowl="./knowl/eq_ortho_proj_formula.html" title="Equation 4.3.2">(4.3.2)</a>:</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_proj_formula.html" id="md-209">
\begin{align*}
\proj{c\boldv+d\boldw}{W} \amp=\sum_{i=1}^{r}\frac{\langle c\boldv+d\boldw, \boldv_i\rangle}{\langle\boldv_i, \boldv_i\rangle }\boldv_i \\
\amp=\sum_{i=1}^r\frac{c\langle \boldv,\boldv_i\rangle+d\langle \boldw, \boldv_i\rangle}{\langle \boldv_i, \boldv_i\rangle}\boldv_i \\
\amp =c\sum_{i=1}^r\frac{\angvec{\boldv, \boldv_i}}{\angvec{\boldv_i, \boldv_i}}\boldv_i+d\sum_{i=1}^r\frac{\angvec{\boldw, \boldv_i}}{\angvec{\boldv_i, \boldv_i}}\boldv_i\\
\amp = c\,\proj{\boldv}{W}+d\,\proj{\boldw}{W}\text{.}
\end{align*}
</div>
</div></li>
<li id="li-918">
<div class="para" id="p-3097">By definition we have <span class="process-math">\(\proj{\boldv}{W}\in W\)</span> for all <span class="process-math">\(\boldv\in W\text{,}\)</span> and thus <span class="process-math">\(\im \operatorname{proj}_W \subseteq W\text{.}\)</span> For the other direction, if <span class="process-math">\(\boldw\in W\text{,}\)</span> then <span class="process-math">\(\boldw=\proj{\boldw}{W}\)</span> (<a href="" class="xref" data-knowl="./knowl/ex_orthoproj_props.html" title="Exercise 4.3.6.12">Exercise¬†4.3.6.12</a>), and thus <span class="process-math">\(\boldw\in \im\operatorname{proj}\text{.}\)</span> This proves <span class="process-math">\(\im\operatorname{proj}=W\text{.}\)</span>
</div>
<div class="para" id="p-3098">The fact that <span class="process-math">\(\NS\operatorname{proj}=W^\perp\)</span> follows from the equivalence stated in (b) of <a href="" class="xref" data-knowl="./knowl/ex_orthoproj_props.html" title="Exercise 4.3.6.12">Exercise¬†4.3.6.12</a>.</div>
</li>
</ol></article></div></section><section class="subsection" id="subsection-68"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.3</span> <span class="title">Orthogonal projection in <span class="process-math">\(\R^2\)</span> and <span class="process-math">\(\R^3\)</span></span>
</h3>
<section class="introduction" id="introduction-68"><div class="para logical" id="p-3099">
<div class="para">For this subsection we will always work within Euclidean space: i.e., <span class="process-math">\(V=\R^n\)</span> with the dot product. In applications we often want to compute the projection of a point onto a line (in <span class="process-math">\(\R^2\)</span> or <span class="process-math">\(\R^3\)</span>) or plane (in <span class="process-math">\(\R^3\)</span>). According to <a href="" class="xref" data-knowl="./knowl/cor_orthoproj_linear.html" title="Corollary 4.3.14: Orthgonal projection is linear">Corollary¬†4.3.14</a> the operation of projecting onto any subspace <span class="process-math">\(W\subseteq \R^n\)</span> is in fact a linear transformation <span class="process-math">\(\operatorname{proj}_W\colon \R^n\rightarrow \R^n\text{.}\)</span> By <a href="" class="xref" data-knowl="./knowl/cor_matrix_transformations.html" title="Corollary 3.6.16: Matrix transformations">Corollary¬†3.6.16</a> we have <span class="process-math">\(\operatorname{proj}_W=T_A\text{,}\)</span> where</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/cor_orthoproj_linear.html ./knowl/cor_matrix_transformations.html ./knowl/eq_ortho_proj_formula.html">
\begin{equation*}
A=\begin{bmatrix}
\vert \amp \vert \amp \amp \vert \\
\proj{\bolde_1}{W}\amp \proj{\bolde_2}{W}\amp \cdots \amp \proj{\bolde_n}{W} \\
\vert \amp \vert \amp \amp \vert
\end{bmatrix}\text{.}
\end{equation*}
</div>
<div class="para">Lastly, <a href="" class="xref" data-knowl="./knowl/eq_ortho_proj_formula.html" title="Equation 4.3.2">(4.3.2)</a> gives us an easy formula for computing <span class="process-math">\(\proj{\bolde_j}{W}\)</span> for all <span class="process-math">\(j\text{,}\)</span> once we have selected an orthogonal basis for <span class="process-math">\(W\text{.}\)</span> As a result we can easily derive matrix formulas for projection onto any subspace <span class="process-math">\(W\)</span> of any Euclidean space <span class="process-math">\(\R^n\text{.}\)</span> We illustrate this with some examples in <span class="process-math">\(\R^2\)</span> and <span class="process-math">\(\R^3\)</span> below.</div>
</div></section><article class="example example-like" id="eg_projection_line"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.15</span><span class="period">.</span><span class="space"> </span><span class="title">Projection onto a line <span class="process-math">\(\ell\subseteq \R^3\)</span>.</span>
</h4>
<div class="para logical" id="p-3100">
<div class="para">Any line in <span class="process-math">\(\R^3\)</span> passing through the origin can be described as <span class="process-math">\(\ell=\Span\{\boldv\}\text{,}\)</span> for some <span class="process-math">\(\boldv=(a,b,c)\ne 0\text{.}\)</span> The set <span class="process-math">\(\{(a,b,c)\}\)</span> is trivially an orthogonal basis of <span class="process-math">\(\ell\text{.}\)</span> Using <a href="" class="xref" data-knowl="./knowl/eq_ortho_proj_formula.html" title="Equation 4.3.2">(4.3.2)</a>, we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_proj_formula.html">
\begin{equation*}
\proj{\boldx}{\ell}=\frac{\boldx\cdot \boldv}{\boldv\cdot\boldv}\boldv=\frac{ax+by+cz}{a^2+b^2+c^2}(a,b,c)\text{.}
\end{equation*}
</div>
<div class="para">It follows that <span class="process-math">\(\operatorname{proj}_\ell=T_A\text{,}\)</span> where</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_proj_formula.html">
\begin{equation*}
A=\begin{bmatrix}
\vert \amp \vert \amp \vert \\
\proj{(1,0,0)}{\ell}\amp \proj{(0,1,0)}{\ell}\amp \proj{(0,0,1)}{\ell} \\
\vert \amp \vert \amp \vert
\end{bmatrix}=\frac{1}{a^2+b^2+c}\begin{bmatrix}
a^2\amp ab\amp ac\\
ab\amp b^2\amp bc\\
ac\amp bc\amp c^2
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></article><article class="example example-like" id="example-95"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.16</span><span class="period">.</span>
</h4>
<div class="para" id="p-3101">Consider the line <span class="process-math">\(\ell=\Span\{(1,2,1)\}\subseteq \R^3\text{.}\)</span>
</div> <ol class="decimal">
<li id="li-919"><div class="para" id="p-3102">Find the matrix <span class="process-math">\(A\)</span> such that <span class="process-math">\(\operatorname{proj}_\ell=T_A\text{.}\)</span>
</div></li>
<li id="li-920"><div class="para" id="p-3103">Use your matrix formula from (a) to compute <span class="process-math">\(\proj{(-2,3,1)}{\ell}\text{,}\)</span> <span class="process-math">\(\proj{(-2,-4,-2)}{\ell}\text{,}\)</span> and  <span class="process-math">\(\proj{(1,-1,1)}{\ell}\text{.}\)</span>
</div></li>
<li id="li-921"><div class="para" id="p-3104">Compute <span class="process-math">\(d((-2,3,1), \ell)\)</span> and <span class="process-math">\(d((-2,-4,-2), \ell)\text{.}\)</span>
</div></li>
</ol>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-96" id="solution-96"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-96"><div class="solution solution-like"><ol class="decimal">
<li id="li-922"><div class="para logical" id="p-3105">
<div class="para">Using the general formula described in <a href="" class="xref" data-knowl="./knowl/eg_projection_line.html" title="Example 4.3.15: Projection onto a line \ell\subseteq \R^3">Example¬†4.3.15</a>, we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_projection_line.html">
\begin{equation*}
A=\frac{1}{6}\begin{bmatrix}
1\amp 2\amp 1\\ 2\amp 4\amp 2\\ 1\amp 2\amp 1
\end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-923"><div class="para logical" id="p-3106">
<div class="para">Now compute</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/ex_orthoproj_props.html" id="md-210">
\begin{align*}
\proj{(-2,3,1)}{\ell}\amp=  \frac{1}{6}\begin{bmatrix}
1\amp 2\amp 1\\ 2\amp 4\amp 2\\ 1\amp 2\amp 1
\end{bmatrix}
\begin{amatrix}[r]
-2 \\ 3\\ 1
\end{amatrix}=
\frac{1}{6}\begin{amatrix}[r]
5\\ 10\\ 5
\end{amatrix}\\
\proj{(-2,-4,-2)}{\ell}\amp=  \frac{1}{6}\begin{bmatrix}
1\amp 2\amp 1\\ 2\amp 4\amp 2\\ 1\amp 2\amp 1
\end{bmatrix}
\begin{amatrix}[r]
-2 \\ -4\\ -2
\end{amatrix}=
\frac{1}{6}\begin{amatrix}[r]
-2\\ -4\\ -2
\end{amatrix}\\
\proj{(1,-1,1)}{\ell}\amp=  \frac{1}{6}\begin{bmatrix}
1\amp 2\amp 1\\ 2\amp 4\amp 2\\ 1\amp 2\amp 1
\end{bmatrix}
\begin{amatrix}[r]
1\\ -1\\ 1
\end{amatrix}=
\frac{1}{6}\begin{amatrix}[r]
0\\ 0\\ 0
\end{amatrix}\text{.}
\end{align*}
</div>
<div class="para">The last two computations, <span class="process-math">\(\proj{(-2,-4,-2)}{\ell}=(-2,-4,-2)\)</span> and <span class="process-math">\(\proj{(1,-1,1)}{\ell}=(0,0,0)\text{,}\)</span> should come as no surprise, since <span class="process-math">\((-2,-4,-2)\in \ell\)</span> and <span class="process-math">\((1,-1,1)\in \ell^\perp\text{.}\)</span> (See <a href="" class="xref" data-knowl="./knowl/ex_orthoproj_props.html" title="Exercise 4.3.6.12">Exercise¬†4.3.6.12</a>.)</div>
</div></li>
<li id="li-924"><div class="para logical" id="p-3107">
<div class="para">We have</div>
<div class="displaymath process-math" id="md-211">
\begin{align*}
d((-2,3,1), \ell) \amp=\norm{(-2,3,1)-\proj{(-2,3,1)}{\ell}} \\
\amp = \norm{\frac{1}{6}(-17,8,1)}=\frac{\sqrt{354}}{6} \\
d((-2,-4,-2), \ell) \amp=\norm{(-2,-4,-2)-\proj{(-2,-4,-2)}{\ell}} \\
\amp = \norm{(0,0,0)}=0 \text{.}
\end{align*}
</div>
<div class="para">Again, the second computation should come as no surprise.  Since <span class="process-math">\((-2,-4,-2)\)</span> is itself an element of <span class="process-math">\(\ell\text{,}\)</span> it stands to reason that its distance to <span class="process-math">\(\ell\)</span> is equal to zero.</div>
</div></li>
</ol></div></div>
</div></article><article class="example example-like" id="eg_projection_plane"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.17</span><span class="period">.</span><span class="space"> </span><span class="title">Projection onto planes in <span class="process-math">\(\R^3\)</span>.</span>
</h4>
<div class="para logical" id="p-3108">
<div class="para">Any plane <span class="process-math">\(W\subseteq\R^3\)</span> passing through the origin can be described as <span class="process-math">\(W=\{(x,y,z)\in \R^3\colon ax+by+cz=0\}\text{.}\)</span> Equivalently, <span class="process-math">\(W\)</span> is the set of all <span class="process-math">\(\boldx\in \R^3\)</span> satisfying <span class="process-math">\(\boldx\cdot (a,b,c)=0\text{:}\)</span> i.e., <span class="process-math">\(W=\ell^\perp\text{,}\)</span> where <span class="process-math">\(\ell=\Span\{(a,b,c)\text{.}\)</span> Consider the orthogonal decomposition with respect to <span class="process-math">\(\ell\text{:}\)</span>
</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_projection_line.html">
\begin{equation*}
\boldx=\proj{\boldx}{\ell}+(\boldx-\proj{\boldx}{\ell})\text{.}
\end{equation*}
</div>
<div class="para">Since <span class="process-math">\(\boldx-\proj{\boldx}{\ell}\in \ell^\perp=W\)</span> and <span class="process-math">\(\proj{\boldx}{\ell}\in \ell=W^\perp\text{,}\)</span> we see that this is also an orthogonal decomposition with respect to <span class="process-math">\(W\text{!}\)</span> Using the matrix formula for <span class="process-math">\(\operatorname{proj}_\ell\)</span> from <a href="" class="xref" data-knowl="./knowl/eg_projection_line.html" title="Example 4.3.15: Projection onto a line \ell\subseteq \R^3">Example¬†4.3.15</a>, we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_projection_line.html" id="md-212">
\begin{align*}
\proj{\boldx}{W} \amp =\boldx-\proj{\boldx}{\ell} \\
\amp = I\boldx -  A\boldx\amp \left(A=\frac{1}{a^2+b^2+c}\begin{bmatrix}
a^2\amp ab\amp ac\\
ab\amp b^2\amp bc\\
ac\amp bc\amp c^2
\end{bmatrix}\right)\\
\amp = (I-A)\boldx\\
\amp = \frac{1}{a^2+b^2+c^2}\begin{bmatrix}b^2+c^2\amp -ab\amp -ac\\ -ab\amp a^2+c^2\amp -bc\\ -ac\amp -bc\amp a^2+b^2 \end{bmatrix}\text{.}
\end{align*}
</div>
<div class="para">We conclude that <span class="process-math">\(\operatorname{proj}_W=T_B\text{,}\)</span> where</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_projection_line.html">
\begin{equation*}
B=\frac{1}{a^2+b^2+c^2}\begin{bmatrix}b^2+c^2\amp -ab\amp -ac\\ -ab\amp a^2+c^2\amp -bc\\ -ac\amp -bc\amp a^2+b^2 \end{bmatrix}\text{.}
\end{equation*}
</div>
</div></article><article class="example example-like" id="example-97"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.18</span><span class="period">.</span>
</h4>
<div class="para" id="p-3109">Consider the plane <span class="process-math">\(W=\{(x,y,z)\in\R^3\colon x-2y+z=0-\}\text{.}\)</span>
</div> <ol class="decimal">
<li id="li-925"><div class="para" id="p-3110">Find the matrix <span class="process-math">\(A\)</span> such that <span class="process-math">\(\operatorname{proj}_W=T_A\text{.}\)</span>
</div></li>
<li id="li-926"><div class="para" id="p-3111">Use your matrix formula from (a) to compute <span class="process-math">\(\proj{(2,1,1)}{W}\)</span> and <span class="process-math">\(\proj{(1,1,1)}{W}\text{.}\)</span>
</div></li>
<li id="li-927"><div class="para" id="p-3112">Compute <span class="process-math">\(d((2,1,1),W)\)</span> and <span class="process-math">\(d((1,1,1), W)\text{.}\)</span>
</div></li>
</ol>
<div class="solutions">
<a href="" data-knowl="" class="id-ref solution-knowl original" data-refid="hk-solution-97" id="solution-97"><span class="type">Solution</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-solution-97"><div class="solution solution-like"><ol class="decimal">
<li id="li-928"><div class="para logical" id="p-3113">
<div class="para">Using the general formula described in <a href="" class="xref" data-knowl="./knowl/eg_projection_plane.html" title="Example 4.3.17: Projection onto planes in \R^3">Example¬†4.3.17</a>, we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_projection_plane.html">
\begin{equation*}
A=\frac{1}{6}\begin{amatrix}[rrr]
5\amp 2\amp -1\\ 2\amp 2\amp 2\\ -1\amp 2\amp 5
\end{amatrix}\text{.}
\end{equation*}
</div>
</div></li>
<li id="li-929"><div class="para logical" id="p-3114">
<div class="para">Now compute</div>
<div class="displaymath process-math" id="md-213">
\begin{align*}
\proj{(2,1,1)}{\ell}\amp= \frac{1}{6}\begin{amatrix}[rrr]
5\amp 2\amp -1\\ 2\amp 2\amp 2\\ -1\amp 2\amp 5
\end{amatrix}
\begin{amatrix}[r]
2 \\ 1\\ 1
\end{amatrix}=
\frac{1}{6}\begin{amatrix}[r]
11\\ 8\\ 5
\end{amatrix}\\
\proj{(1,1,1)}{\ell}\amp= \frac{1}{6}\begin{amatrix}[rrr]
5\amp 2\amp -1\\ 2\amp 2\amp 2\\ -1\amp 2\amp 5
\end{amatrix}
\begin{amatrix}[r]
1 \\ 1\\ 1
\end{amatrix}=
\frac{1}{6}\begin{amatrix}[r]
0\\ 0\\ 0
\end{amatrix}\text{.}
\end{align*}
</div>
</div></li>
<li id="li-930"><div class="para logical" id="p-3115">
<div class="para">We have</div>
<div class="displaymath process-math" id="md-214">
\begin{align*}
d((2,1,1), W) \amp = \norm{(2,1,1)-\proj{(2,1,1)}{W}}\\
\amp =\norm{\frac{1}{6}(1,-2,-1)}=\frac{6}{6} \\
d((1,1,1), W) \amp = \norm{(1,1,1)-\proj{(1,1,1)}{W}}\\
\amp =\norm{(0,0,0)}=0 \text{.}
\end{align*}
</div>
</div></li>
</ol></div></div>
</div></article></section><section class="subsection" id="subsection-69"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.4</span> <span class="title">Trigonometric polynomial approximation</span>
</h3>
<div class="para logical" id="p-3116">
<div class="para">Consider the inner product space consisting of  <span class="process-math">\(C([0,2\pi])\)</span> along with the integral inner product <span class="process-math">\(\langle f, g\rangle=\int_0^{2\pi}f(x)g(x) \, dx\text{.}\)</span> In <a href="" class="xref" data-knowl="./knowl/eg_orthogonal_functions.html" title="Example 4.2.4">Example¬†4.2.4</a> we saw that the set</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_orthogonal_functions.html">
\begin{equation*}
B=\{1, \cos(x),\sin(x),\cos(2x),\sin(2x), \dots , \cos(nx),\sin(nx)\}
\end{equation*}
</div>
<div class="para">is orthogonal with respect to this inner product. Thus <span class="process-math">\(B\)</span> is an orthogonal basis of</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_orthogonal_functions.html">
\begin{equation*}
\Span B=\{g\in C([0,2\pi])\colon g(x)=a_0+\sum_{k=1}^na_k\cos kx +b_k\sin kx \text{ for some } a_i, b_i\in \R\}\text{.}
\end{equation*}
</div>
<div class="para">We call <span class="process-math">\(W=\Span B\)</span> the space of <dfn class="terminology">trigonometric polynomials of degree at most <span class="process-math">\(n\)</span></dfn>.</div>
</div>
<div class="para logical" id="p-3117">
<div class="para">Since <span class="process-math">\(B\)</span> is an orthogonal basis of <span class="process-math">\(W\text{,}\)</span> given an arbitrary function <span class="process-math">\(f(x)\in C[0,2\pi]\text{,}\)</span> its orthogonal projection <span class="process-math">\(\hat{f}=\proj{f}{W}\)</span> is given by</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_proj_formula.html ./knowl/eg_orthogonal_functions.html">
\begin{equation*}
\hat{f}(x)=a_0+a_1\cos(x)+b_1\sin(x)+a_2\cos(2x)+b_2\sin(2x)+\cdots +a_n\cos(nx)+b_n\sin(nx)\text{,}
\end{equation*}
</div>
<div class="para">where</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_proj_formula.html ./knowl/eg_orthogonal_functions.html">
\begin{equation*}
a_0=\frac{1}{2\pi}\int_0^{2\pi} f(x) \ dx, \ a_j=\frac{1}{\pi}\int_0^{2\pi}f(x)\cos(jx)\, dx, \ b_k=\frac{1}{\pi}\int_0^{2\pi}f(x)\sin(kx)\, dx\text{.}
\end{equation*}
</div>
<div class="para">Here we are using <a href="" class="xref" data-knowl="./knowl/eq_ortho_proj_formula.html" title="Equation 4.3.2">(4.3.2)</a>, as well as the inner product formulas <span class="process-math">\(\angvec{1,1}=2\pi\)</span> and <span class="process-math">\(\angvec{\cos n x, \cos n x}=\angvec{\sin n x, \sin n x}=\pi\)</span> from <a href="" class="xref" data-knowl="./knowl/eg_orthogonal_functions.html" title="Example 4.2.4">Example¬†4.2.4</a>.</div>
</div>
<div class="para logical" id="p-3118">
<div class="para">What is the relationship between <span class="process-math">\(f\)</span> and <span class="process-math">\(\hat{f}\text{?}\)</span> <a href="" class="xref" data-knowl="./knowl/th_orthogonal_projection.html" title="Theorem 4.3.9: Orthogonal projection theorem">Theorem¬†4.3.9</a> tells us that <span class="process-math">\(\hat{f}\)</span> is the ‚Äúbest‚Äù trigonometric polynomial approximation of <span class="process-math">\(f(x)\)</span> of degree at most <span class="process-math">\(n\)</span> in the following sense: given any any other trigonometric polynomial <span class="process-math">\(g\in W\text{,}\)</span> we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_orthogonal_projection.html">
\begin{equation*}
\left\vert\left\vert f-\hat{f}\right\vert\right\vert\leq \norm{f-g}\text{.}
\end{equation*}
</div>
<div class="para">Unpacking the definition of norm in this inner product space, we conclude that</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_orthogonal_projection.html">
\begin{equation*}
\int_0^{2\pi} (f-\hat{f})^2\, dx\leq \int_0^{2\pi} (f-g)^2 \, dx
\end{equation*}
</div>
<div class="para">for all <span class="process-math">\(g\in W\text{.}\)</span>
</div>
</div>
<div class="para logical" id="p-3119">
<div class="para">Thus, given a continuous function <span class="process-math">\(f\)</span> on <span class="process-math">\([0,2\pi]\text{,}\)</span> linear algebra shows us how to find its best trigonometric polynomial approximation of the form</div>
<div class="displaymath process-math">
\begin{equation*}
g(x)=a_0+\sum_{k=1}^na_k\cos kx +b_k\sin kx\text{.}
\end{equation*}
</div>
<div class="para">However, linear algebra does not tell us just how good this approximation is. This question, among others, is tackled by another mathematical theory: <em class="emphasis">Fourier analysis</em>. There we learn that the trigonometric polynomial approximations get arbitrarily close to <span class="process-math">\(f\)</span> as we let <span class="process-math">\(n\)</span> increase. More precisely, letting <span class="process-math">\(\hat{f}_n\)</span> be the orthogonal projection of <span class="process-math">\(f\)</span> onto the space of trigonometric polynomials of degree at most <span class="process-math">\(n\text{,}\)</span> we have</div>
<div class="displaymath process-math">
\begin{equation*}
\lim_{n\to\infty}\norm{f-\hat{f}_n}=0\text{.}
\end{equation*}
</div>
</div></section><section class="subsection" id="subsection-70"><h3 class="heading hide-type">
<span class="type">Subsection</span> <span class="codenumber">4.3.5</span> <span class="title">Least-squares solution to linear systems</span>
</h3>
<div class="para logical" id="p-3120">
<div class="para">In statistics we often wish to approximate a scatter plot of points <span class="process-math">\(P_i=(X_i, Y_i)\text{,}\)</span> <span class="process-math">\(1\leq i\leq m\text{,}\)</span> with a line <span class="process-math">\(\ell\colon y=mx+b\)</span> that ‚Äúbest fits‚Äù the data. ‚ÄúFinding‚Äù this line amounts to finding the appropriate slope <span class="process-math">\(m\)</span> and <span class="process-math">\(y\)</span>-intercept <span class="process-math">\(b\text{:}\)</span> i.e., in this setup, the points <span class="process-math">\(P_i=(X_i, Y_i)\)</span> are given, and <span class="process-math">\(m\)</span> and <span class="process-math">\(b\)</span> are the unknowns we wish to find. For the line to perfectly fit the data, we would want</div>
<div class="displaymath process-math">
\begin{equation*}
Y_i=mX_i+b \text{ for all } 1\leq i\leq m\text{.}
\end{equation*}
</div>
<div class="para">In other words <span class="process-math">\((m,b)\)</span> would be a solution to the matrix equation <span class="process-math">\(A\boldx=\boldy\text{,}\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
\boldx=\begin{bmatrix}m \\ b\end{bmatrix},A=\begin{bmatrix} X_1\amp 1\\ X_2\amp 1\\ \vdots \amp \vdots \\ X_m\amp 1  \end{bmatrix},  \boldy=\begin{bmatrix} Y_1\\ Y_2\\ \vdots \\ Y_m\end{bmatrix}\text{.}
\end{equation*}
</div>
<div class="para">Of course in most situations the provided points do not lie on a line, and thus there is no solution <span class="process-math">\(\boldx\)</span> to the given matrix equation <span class="process-math">\(A\boldx=\boldy\text{.}\)</span> When this is the case we can use the theory of orthogonal projection to find what is called a <em class="emphasis">least-squares</em> solution, which we now describe in detail.</div>
</div>
<div class="para logical" id="p-3121">
<div class="para">The least-squares method applies to any matrix equation</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_fundspaces_matrixtransform.html ./knowl/eq_least-squares_orig.html ./knowl/eq_least-squares_new.html ./knowl/eq_least-squares_orig.html" id="eq_least-squares_orig">
\begin{equation}
\underset{m\times n}{A}\, \underset{n\times 1}{\boldx}=\underset{m\times 1}{\boldy}\text{,}\tag{4.3.5}
\end{equation}
</div>
<div class="para">where <span class="process-math">\(A\)</span> and <span class="process-math">\(\boldy\)</span> are given, and <span class="process-math">\(\boldx\)</span> is treated as an unknown vector. Recall that</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_fundspaces_matrixtransform.html ./knowl/eq_least-squares_orig.html ./knowl/eq_least-squares_new.html ./knowl/eq_least-squares_orig.html" id="md-215">
\begin{align*}
A\boldx=\boldy \text{ has a solution } \amp\iff \boldy\in \CS A \amp (\knowl{./knowl/th_fundspaces_matrixtransform.html}{\text{Theorem 3.8.6}}) \text{.}
\end{align*}
</div>
<div class="para">When <span class="process-math">\(\boldy\notin \CS A\text{,}\)</span> and hence <a href="" class="xref" data-knowl="./knowl/eq_least-squares_orig.html" title="Equation 4.3.5">(4.3.5)</a> does not have a solution, the least-squares method proceeds by replacing <span class="process-math">\(\boldy\)</span> with the element of <span class="process-math">\(W=\CS A\)</span> closest to it: that is, with its <em class="emphasis">orthogonal projection</em> onto <span class="process-math">\(W\text{.}\)</span>  Let <span class="process-math">\(\hat{\boldy}=\proj{\boldy}{W}\text{,}\)</span> where orthogonal projection is taken with respect to the dot product on <span class="process-math">\(\R^m\text{,}\)</span> and consider the adjusted matrix equation</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_fundspaces_matrixtransform.html ./knowl/eq_least-squares_orig.html ./knowl/eq_least-squares_new.html ./knowl/eq_least-squares_orig.html" id="eq_least-squares_new">
\begin{equation}
A\boldx=\hat{\boldy}\text{.}\tag{4.3.6}
\end{equation}
</div>
<div class="para">By definition of <span class="process-math">\(\operatorname{proj}_W\text{,}\)</span>  we have <span class="process-math">\(\hat{\boldy}\in W=\CS A\text{,}\)</span> and thus there is a solution <span class="process-math">\(\hat{\boldx}\)</span> to <a href="" class="xref" data-knowl="./knowl/eq_least-squares_new.html" title="Equation 4.3.6">(4.3.6)</a>. We call <span class="process-math">\(\hat{\boldx}\)</span> a <dfn class="terminology">least-squares</dfn> solution to <a href="" class="xref" data-knowl="./knowl/eq_least-squares_orig.html" title="Equation 4.3.5">(4.3.5)</a>. Observe that <span class="process-math">\(\hat{\boldx}\)</span> does <em class="emphasis">not</em> necessarily satisfy <span class="process-math">\(A\hat{\boldx}=\boldy\text{;}\)</span> rather, it satisfies <span class="process-math">\(A\hat{\boldx}=\hat{\boldy}\text{.}\)</span> What makes this a ‚Äúleast-squares‚Äù solution is that <span class="process-math">\(A\hat{\boldx}=\hat{\boldy}\)</span> is the element of <span class="process-math">\(W=\CS A\)</span> closest to <span class="process-math">\(\boldy\text{.}\)</span> With respect to the dot product, this means that a least-squares solution <span class="process-math">\(\hat{\boldx}\)</span> minimizes the quantity</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_fundspaces_matrixtransform.html ./knowl/eq_least-squares_orig.html ./knowl/eq_least-squares_new.html ./knowl/eq_least-squares_orig.html">
\begin{equation*}
\norm{\boldy-A\boldx}=\sqrt{(y_1-y_1')^2+(y_2-y_2')^2+\cdots +(y_n-y_n')^2}\text{,}
\end{equation*}
</div>
<div class="para">among all <span class="process-math">\(\boldx\in \R^n\text{.}\)</span>
</div>
</div>
<article class="example example-like" id="eg_least-squares"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.19</span><span class="period">.</span><span class="space"> </span><span class="title">Best fitting line.</span>
</h4>
<div class="para logical" id="p-3122">
<div class="para">Suppose we wish to find a line <span class="process-math">\(\ell\colon y=mx+b\)</span> that best fits (in the least-square sense) the following data points: <span class="process-math">\(P_1=(-3,1), P_2=(1,2), P_3=(2,3)\text{.}\)</span> Following the discussion above, we seek a solution <span class="process-math">\(\boldx=(m,b)\)</span> to the matrix equation <span class="process-math">\(A\boldx=\boldy\text{,}\)</span> where</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_proj_formula.html">
\begin{equation*}
\boldx=\begin{bmatrix}m \\ b \end{bmatrix}, A=\begin{amatrix}[rr]-3\amp 1\\ 1\amp 1\\ 2\amp 1 \end{amatrix}  , \boldy=\begin{bmatrix}1\\ 2\\ 3 \end{bmatrix}\text{.}
\end{equation*}
</div>
<div class="para">Using Gaussian elimination, we see easily that this equation has no solution: equivalently, <span class="process-math">\(\boldy\notin W=\CS A\text{.}\)</span> Accordingly, we compute <span class="process-math">\(\hat{\boldy}=\proj{\boldy}{W}\)</span> and find a solution to <span class="process-math">\(A\hat{\boldx}=\hat{\boldy}\text{.}\)</span> Conveniently, the set <span class="process-math">\(B=\{(-3,2,1), (1,1,1)\}\)</span> is already an <em class="emphasis">orthogonal</em> basis of <span class="process-math">\(W=\CS A\text{,}\)</span> allowing us to use <a href="" class="xref" data-knowl="./knowl/eq_ortho_proj_formula.html" title="Equation 4.3.2">(4.3.2)</a>:</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_ortho_proj_formula.html">
\begin{equation*}
\hat{\boldy}=\frac{\boldy\cdot (-3,1,2)}{(-3,2,1)\cdot (-3,1,2)}(-3,1,2)+\frac{\boldy\cdot(1,1,1)}{(1,1,1)\cdot (1,1,1)}(1,1,1)=\frac{1}{14}(13, 33, 38)\text{.}
\end{equation*}
</div>
<div class="para">Lastly, solving <span class="process-math">\(A\hat{\boldx}=\hat{\boldy}\)</span> yields <span class="process-math">\((m,b)=\hat{\boldx}=(5/14, 2)\text{,}\)</span> and we conclude the line <span class="process-math">\(\ell\colon y=(5/14)x+2\)</span> is the one that best fits the data in the least-squares sense.</div>
</div></article><article class="remark remark-like" id="rm_least-squares"><h4 class="heading">
<span class="type">Remark</span><span class="space"> </span><span class="codenumber">4.3.20</span><span class="period">.</span><span class="space"> </span><span class="title">Visualizing least-squares.</span>
</h4> <div class="para logical" id="p-3123">
<div class="para">
<a href="" class="xref" data-knowl="./knowl/fig_leastsquares.html" title="Figure 4.3.21: Least-squares visualization">Figure¬†4.3.21</a> helps us give a graphical interpretation of how the line <span class="process-math">\(\ell\colon y=(5/14)x+2\)</span> best approximates the points <span class="process-math">\(P_1=(-3,1), P_2=(1,2), P_3=(2,3)\text{.}\)</span> <figure class="figure figure-like" id="fig_leastsquares"><div class="image-box" style="width: 100%; margin-left: 0%; margin-right: 0%;"><img src="external/images/im_leastsquares.svg" role="img" class="contained"></div>
<figcaption><span class="type">Figure</span><span class="space"> </span><span class="codenumber">4.3.21<span class="period">.</span></span><span class="space"> </span>Least-squares visualization</figcaption></figure> Let <span class="process-math">\(\boldy=(1,2,3)=(y_1,y_2,y_3)\)</span> be the given <span class="process-math">\(y\)</span>-values of the points, and let <span class="process-math">\(\hat{\boldy}=(y_1',y_2',y_3')\)</span> be the orthogonal projection of <span class="process-math">\(\boldy\)</span> onto <span class="process-math">\(\CS A\text{.}\)</span> In the graph the values <span class="process-math">\(\epsilon_i\)</span> denote the vertical difference <span class="process-math">\(\epsilon_i=y_i-y_i'\)</span> between the data points, and our fitting line. The projection <span class="process-math">\(\hat{\boldy}\)</span> makes the error <span class="process-math">\(\norm{\boldy-\hat{\boldy}}=\sqrt{ \epsilon_1^2+\epsilon_2^2+\epsilon_3^2}\)</span> as small as possible. This means if I draw <em class="emphasis">any other line</em> and compute the corresponding differences <span class="process-math">\(\epsilon_i'\)</span> at the <span class="process-math">\(x\)</span>-values  -3, 1 and 2, then</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/fig_leastsquares.html">
\begin{equation*}
\epsilon_1^2+\epsilon_2^2+\epsilon_3^2\leq (\epsilon_1')^2+(\epsilon_2')^2+(\epsilon_3')^2
\end{equation*}
</div>
</div></article><div class="para logical" id="p-3124">
<div class="para">To compute a least-squares solution to <span class="process-math">\(A\boldx=\boldy\)</span> we must first compute the orthogonal projection of <span class="process-math">\(\boldy\)</span> onto <span class="process-math">\(W=\CS A\text{;}\)</span> and this in turn requires first producing an orthogonal basis of <span class="process-math">\(\CS A\text{,}\)</span> which may require using the Gram-Schmidt procedure. The following result bypasses these potentially onerous steps by  characterizing a least-squares solution to <span class="process-math">\(A\boldx=\boldy\)</span> as a solution to the matrix equation</div>
<div class="displaymath process-math">
\begin{equation*}
A^TA\boldx=A^T\boldy\text{.}
\end{equation*}
</div>
</div>
<article class="theorem theorem-like" id="th_leastsquares"><h4 class="heading">
<span class="type">Theorem</span><span class="space"> </span><span class="codenumber">4.3.22</span><span class="period">.</span><span class="space"> </span><span class="title">Least-squares matrix formula.</span>
</h4>
<div class="para logical" id="p-3125">
<div class="para">Given an <span class="process-math">\(m\times n\)</span> matrix <span class="process-math">\(A\)</span> and <span class="process-math">\(m\times 1\)</span> column vector <span class="process-math">\(\boldy\text{,}\)</span> a vector <span class="process-math">\(\hat{\boldx}\)</span> is a least-squares solution to <span class="process-math">\(A\boldx=\boldy\)</span> if and only if</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eq_leastsquares_matrix_equation.html" id="eq_leastsquares_matrix_equation">
\begin{equation}
A^TA\boldx=A^T\boldy\text{.}\tag{4.3.7}
\end{equation}
</div>
<div class="para">In other words, we can find a least-squares solution by solving the matrix equation <a href="" class="xref" data-knowl="./knowl/eq_leastsquares_matrix_equation.html" title="Equation 4.3.7">(4.3.7)</a> directly.</div>
</div></article><article class="hiddenproof" id="proof-84"><a href="" data-knowl="" class="id-ref proof-knowl original" data-refid="hk-proof-84"><h4 class="heading"><span class="type">Proof<span class="period">.</span></span></h4></a></article><div class="hidden-content tex2jax_ignore" id="hk-proof-84"><article class="hiddenproof"><div class="para logical" id="p-3126">
<div class="para">Let <span class="process-math">\(W=\CS A\text{,}\)</span> and let <span class="process-math">\(\hat{\boldy}=\proj{\boldy}{W}\text{.}\)</span> The key observation is that a vector <span class="process-math">\(\hat{\boldx}\)</span> satisfies <span class="process-math">\(A\hat{\boldx}=\hat{\boldy}\)</span> if and only if</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_row_null_comp.html">
\begin{equation*}
\boldy=A\hat{\boldx}+(\boldy-A\hat{\boldx})
\end{equation*}
</div>
<div class="para">is an orthogonal decomposition of <span class="process-math">\(\boldy\)</span> with respect to <span class="process-math">\(W=\CS A\text{;}\)</span> and this is true if and only if <span class="process-math">\(\boldy-A\hat{\boldx}\in (\CS A)^\perp\text{.}\)</span> Thus we have</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_row_null_comp.html" id="md-216">
\begin{align*}
A\hat{\boldx}=\hat{\boldy} \amp\iff \boldy-A\hat{\boldx}\in (\CS A)^\perp \\
\amp\iff \boldy-A\hat{\boldx}\in \NS A^T \amp ((\CS A)^\perp=\NS A^T, \knowl{./knowl/th_row_null_comp.html}{\text{Theorem 4.3.7}}) \\
\amp\iff A^T(\boldy-A\hat{\boldx})=\boldzero \\
\amp \iff A^T\boldy-A^TA\hat{\boldx}=\boldzero\\
\amp \iff A^TA\hat{\boldx}=A^T\boldy\text{.}
\end{align*}
</div>
</div></article></div>
<article class="example example-like" id="example-99"><h4 class="heading">
<span class="type">Example</span><span class="space"> </span><span class="codenumber">4.3.23</span><span class="period">.</span>
</h4>
<div class="para logical" id="p-3127">
<div class="para">Consider again the matrix equation <span class="process-math">\(A\boldx=\boldy\)</span> from <a href="" class="xref" data-knowl="./knowl/eg_least-squares.html" title="Example 4.3.19: Best fitting line">Example¬†4.3.19</a>. According to <a href="" class="xref" data-knowl="./knowl/th_leastsquares.html" title="Theorem 4.3.22: Least-squares matrix formula">Theorem¬†4.3.22</a> the least-squares solution can be found by solving the equation <span class="process-math">\(A^TA\boldx=A^T\boldy\)</span> for <span class="process-math">\(\boldx\text{.}\)</span> We compute</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_least-squares.html ./knowl/th_leastsquares.html" id="md-217">
\begin{align*}
A^TA\amp=\begin{amatrix}[rr]14\amp 0\\ 0\amp 3  \end{amatrix} \amp A^T\boldy\amp =\begin{amatrix}[r] 5\\ 6 \end{amatrix}
\end{align*}
</div>
<div class="para">and solve</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/eg_least-squares.html ./knowl/th_leastsquares.html">
\begin{equation*}
\begin{amatrix}[rr]14\amp 0\\ 0\amp 3  \end{amatrix}\boldx=\begin{amatrix}[r] 5\\ 6 \end{amatrix}\iff
\boldx=(5/14, 2),
\end{equation*}
</div>
<div class="para">just as before.</div>
</div></article></section><section class="exercises" id="s_orthogonal_projection_ex"><h3 class="heading hide-type">
<span class="type">Exercises</span> <span class="codenumber">4.3.6</span> <span class="title">Exercises</span>
</h3>
<div class="exercisegroup" id="exercisegroup-30">
<h4 class="heading"><span class="title">.</span></h4>
<div class="introduction" id="introduction-69">In each exercise below you are given an inner product space <span class="process-math">\(V\text{,}\)</span> a subspace <span class="process-math">\(W=\Span B\)</span> where <span class="process-math">\(B\)</span> is orthogonal, and a vector <span class="process-math">\(\boldv\in V\text{.}\)</span> Compute <span class="process-math">\(\proj{\boldv}{W}\text{.}\)</span>
</div>
<div class="exercisegroup-exercises">
<article class="exercise exercise-like" id="exercise-338"><h5 class="heading"><span class="codenumber">1<span class="period">.</span></span></h5>
<div class="para" id="p-3128">
<span class="process-math">\(V=\R^4\)</span> with the dot product; <span class="process-math">\(W=\Span\{(1,1,1,1),(1,-1,1,-1), (1,1,-1,-1)\}\text{;}\)</span> <span class="process-math">\(\boldv=(2,3,-1,1)\)</span>
</div></article><article class="exercise exercise-like" id="exercise-339"><h5 class="heading"><span class="codenumber">2<span class="period">.</span></span></h5>
<div class="para" id="p-3129">
<span class="process-math">\(V=\R^3\)</span> with dot product with weights <span class="process-math">\(k_1=1, k_2=2, k_3=1\text{;}\)</span> <span class="process-math">\(W=\{(1,1,1), (1,-1,1),(1,0,-1)\}\text{;}\)</span> <span class="process-math">\(\boldv=(1,2,3)\)</span>
</div></article><article class="exercise exercise-like" id="exercise-340"><h5 class="heading"><span class="codenumber">3<span class="period">.</span></span></h5>
<div class="para" id="p-3130">
<span class="process-math">\(V=C([0,2\pi])\)</span> with the integral inner product; <span class="process-math">\(W=\Span\{\cos x, \cos 2x, \sin x\}\text{;}\)</span> <span class="process-math">\(f(x)=3\)</span> for all <span class="process-math">\(x\in [0,2\pi]\)</span>
</div></article>
</div>
</div>
<article class="exercise exercise-like" id="exercise-341"><h4 class="heading"><span class="codenumber">4<span class="period">.</span></span></h4>
<div class="para" id="p-3131">Let <span class="process-math">\(\mathcal{P}\subseteq \R^3\)</span> be the plane passing through the origin with normal vector <span class="process-math">\(\boldn=(1,2,-1)\text{.}\)</span> Find the orthogonal projection of <span class="process-math">\((1,1,1)\)</span> onto <span class="process-math">\(\mathcal{P}\)</span> with respect to the dot product.</div></article><article class="exercise exercise-like" id="exercise-342"><h4 class="heading"><span class="codenumber">5<span class="period">.</span></span></h4>
<div class="para" id="p-3132">Recall that the trace <span class="process-math">\(\tr A\)</span> of a square matrix is the sum of its diagonal entries. Let <span class="process-math">\(V=M_{22}\)</span> with inner product <span class="process-math">\(\angvec{A,B}=\tr(A^TB)\text{.}\)</span> (You may take for granted that this operation is indeed an inner product on <span class="process-math">\(M_{22}\text{.}\)</span>) Define <span class="process-math">\(W=\{A\in M_{22}\colon \tr A=0\}\text{.}\)</span>
</div> <ol class="lower-alpha">
<li id="li-931"><div class="para" id="p-3133">Compute an orthogonal basis for <span class="process-math">\(W\text{.}\)</span> You can do this either by inspection (the space is manageable), or by starting with any basis of <span class="process-math">\(W\)</span> and applying the Gram-Schmidt procedure.</div></li>
<li id="li-932"><div class="para logical" id="p-3134">
<div class="para">Compute <span class="process-math">\(\proj{A}{W}\text{,}\)</span> where</div>
<div class="displaymath process-math">
\begin{equation*}
A=\begin{bmatrix}1\amp 2\\ 1\amp 1 \end{bmatrix}\text{.}
\end{equation*}
</div>
</div></li>
</ol></article><article class="exercise exercise-like" id="exercise-343"><h4 class="heading"><span class="codenumber">6<span class="period">.</span></span></h4>
<div class="para" id="p-3135">Let <span class="process-math">\(V=C([0,1])\)</span> with the integral inner product, and let <span class="process-math">\(f(x)=x\text{.}\)</span> Find the function of the form <span class="process-math">\(g(x)=a+b\cos(2\pi x)+c\sin(2\pi x)\)</span> that ‚Äúbest approximates‚Äù <span class="process-math">\(f(x)\)</span> in terms of this inner product: i.e. find the the <span class="process-math">\(g(x)\)</span> of this form that minimizes <span class="process-math">\(d(g,f)\text{.}\)</span>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-27" id="hint-27"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-27"><div class="hint solution-like"><div class="para" id="p-3136">The set <span class="process-math">\(S=\{f(x)=1, g(x)=\cos(2\pi x), h(x)=\sin(2\pi x)\}\)</span> is orthogonal with respect to the given inner product.</div></div></div>
</div></article><article class="exercise exercise-like" id="ex_ortho_comp"><h4 class="heading"><span class="codenumber">7<span class="period">.</span></span></h4>
<div class="para logical" id="p-3137">
<div class="para">Let <span class="process-math">\((V, \langle , \rangle )\)</span> be an inner product space, let <span class="process-math">\(S=\{\boldw_1, \boldw_2, \dots, \boldw_r\}\subseteq V\text{,}\)</span> and let <span class="process-math">\(W=\Span S\text{.}\)</span> Prove:</div>
<div class="displaymath process-math">
\begin{equation*}
\boldv\in W^\perp \text{ if and only if } \langle \boldv,\boldw_i \rangle=0 \text{ for all } 1\leq i\leq r\text{.}
\end{equation*}
</div>
<div class="para">In other words, to check whether an element is in <span class="process-math">\(W^\perp\text{,}\)</span> it suffices to check that it is orthogonal to each element of its spanning set <span class="process-math">\(S\text{.}\)</span>
</div>
</div></article><article class="exercise exercise-like" id="exercise-345"><h4 class="heading"><span class="codenumber">8<span class="period">.</span></span></h4>
<div class="para logical" id="p-3138">
<div class="para">Consider the inner product space <span class="process-math">\(\R^4\)</span> together with the dot product. Let</div>
<div class="displaymath process-math">
\begin{equation*}
W=\{(x_1,x_2,x_3,x_4)\in \R^4\colon x_1=x_3 \text{ and } x_2=x_4\}.
\end{equation*}
</div>
<div class="para">Provide orthogonal bases for <span class="process-math">\(W\)</span> and <span class="process-math">\(W^\perp\text{.}\)</span>
</div>
</div></article><article class="exercise exercise-like" id="ex_orthocomp_subspace"><h4 class="heading"><span class="codenumber">9<span class="period">.</span></span></h4>
<div class="para" id="p-3139">Prove statements (1) and (2) of <a href="" class="xref" data-knowl="./knowl/th_orthogonal_complement.html" title="Theorem 4.3.5: Orthogonal complement">Theorem¬†4.3.5</a>.</div></article><article class="exercise exercise-like" id="ex_orthocomp_dim"><h4 class="heading">
<span class="codenumber">10<span class="period">.</span></span><span class="space"> </span><span class="title">Dimension of <span class="process-math">\(W^\perp\)</span>.</span>
</h4>
<div class="para logical" id="p-3140">
<div class="para">Prove statement (3) of <a href="" class="xref" data-knowl="./knowl/th_orthogonal_complement.html" title="Theorem 4.3.5: Orthogonal complement">Theorem¬†4.3.5</a>:  if <span class="process-math">\((V, \ \angvec{\ , \ })\)</span> is an inner product space of dimension <span class="process-math">\(n\text{,}\)</span> and <span class="process-math">\(W\)</span> is a subspace of <span class="process-math">\(V\text{,}\)</span> then</div>
<div class="displaymath process-math" data-contains-math-knowls="./knowl/th_orthogonal_complement.html">
\begin{equation*}
\dim W+\dim W^\perp=n\text{.}
\end{equation*}
</div>
</div>
<div class="solutions">
<a href="" data-knowl="" class="id-ref hint-knowl original" data-refid="hk-hint-28" id="hint-28"><span class="type">Hint</span><span class="period">.</span></a><div class="hidden-content tex2jax_ignore" id="hk-hint-28"><div class="hint solution-like"><div class="para" id="p-3141">By <a href="" class="xref" data-knowl="./knowl/cor_orthonormal_existence.html" title="Corollary 4.2.10: Existence of orthonormal bases">Corollary¬†4.2.10</a> there is an orthogonal basis <span class="process-math">\(B=\{\boldv_1,\dots ,\boldv_r\}\)</span> of <span class="process-math">\(W\text{,}\)</span> and furthermore, we can extend <span class="process-math">\(B\)</span> to an orthogonal basis <span class="process-math">\(B'=\{\boldv_1,\boldv_2, \dots, \boldv_r, \boldu_1,\dots , \boldu_{n-r}\}\)</span> of all of <span class="process-math">\(V\text{.}\)</span> Show the <span class="process-math">\(\boldu_i\)</span> form a basis for <span class="process-math">\(W^\perp\text{.}\)</span>
</div></div></div>
</div></article><article class="exercise exercise-like" id="exercise-348"><h4 class="heading"><span class="codenumber">11<span class="period">.</span></span></h4>
<div class="para" id="p-3142">Prove <a href="" class="xref" data-knowl="./knowl/cor_orthoproj_linear.html" title="Corollary 4.3.14: Orthgonal projection is linear">Corollary¬†4.3.14</a> following the suggestion in the text.</div></article><article class="exercise exercise-like" id="ex_orthoproj_props"><h4 class="heading"><span class="codenumber">12<span class="period">.</span></span></h4>
<div class="para" id="p-3143">Let <span class="process-math">\(V\)</span> an inner product space, and let <span class="process-math">\(W\subseteq V\)</span> be a finite-dimensional subspace. Prove the following statements:</div> <ol class="lower-alpha">
<li id="li-933"><div class="para" id="p-3144">
<span class="process-math">\(\boldv\in W\)</span> if and only if <span class="process-math">\(\proj{\boldv}{W}=\boldv\text{;}\)</span>
</div></li>
<li id="li-934"><div class="para" id="p-3145">
<span class="process-math">\(\boldv\in W^\perp\)</span> if and only if  <span class="process-math">\(\proj{\boldv}{W}=\boldzero\text{.}\)</span>
</div></li>
</ol></article><article class="exercise exercise-like" id="exercise-350"><h4 class="heading"><span class="codenumber">13<span class="period">.</span></span></h4>
<div class="para" id="p-3146">We consider the problem of fitting a collection of data points <span class="process-math">\((x,y)\)</span> with a quadratic curve of the form <span class="process-math">\(y=f(x)=ax^2+bx+c\text{.}\)</span> Thus we are <em class="emphasis">given</em> some collection of points <span class="process-math">\((x,y)\text{,}\)</span> and we <em class="emphasis">seek</em> parameters <span class="process-math">\(a,
b, c\)</span> for which the graph of <span class="process-math">\(f(x)=ax^2+bx+c\)</span> ‚Äúbest fits‚Äù the points in some way.</div> <ol class="lower-alpha">
<li id="li-935"><div class="para" id="p-3147">Show, using linear algebra, that if we are given any three points <span class="process-math">\((x,y)=(r_1,s_1), (r_2,s_2), (r_3,s_3)\text{,}\)</span> where the <span class="process-math">\(x\)</span>-coordinates <span class="process-math">\(r_i\)</span> are all distinct, then there is a <em class="emphasis">unique</em> choice of <span class="process-math">\(a,b,c\)</span> such that the corresponding quadratic function agrees <em class="emphasis">precisely</em> with the data. In other words, given just about any three points in the plane, there is a unique quadratic curve connecting them.</div></li>
<li id="li-936">
<div class="para logical" id="p-3148">
<div class="para">Now suppose we are given the four data points</div>
<div class="displaymath process-math">
\begin{equation*}
P_1=(0,2), P_2=(1,0), P_3=(2,2), P_4=(3,6)\text{.}
\end{equation*}
</div>
</div>
<ol class="lower-roman">
<li id="li-937"><div class="para" id="p-3149">Use the least-squares method described in the lecture notes to come up with a quadratic function <span class="process-math">\(y=f(x)\)</span> that ‚Äúbest fits‚Äù the data.</div></li>
<li id="li-938"><div class="para" id="p-3150">Graph the function <span class="process-math">\(f\)</span> you found, along with the points <span class="process-math">\(P_i\text{.}\)</span> (You may want to use technology.) Use your graph to explain precisely in what sense <span class="process-math">\(f\)</span> ‚Äúbest fits‚Äù the data.</div></li>
</ol>
</li>
</ol></article></section></section></div>
<div class="ptx-content-footer">
<a class="previous-button button" href="s_orthogonality.html" title="Previous"><span class="icon">&lt;</span><span class="name">Prev</span></a><a class="top-button button" href="#" title="Top"><span class="icon">^</span><span class="name">Top</span></a><a class="next-button button" href="c_transbasis.html" title="Next"><span class="name">Next</span><span class="icon">&gt;</span></a>
</div></main>
</div>
<div id="ptx-page-footer" class="ptx-page-footer">
<a class="pretext-link" href="https://pretextbook.org" title="PreTeXt"><div class="logo"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="338 3000 8772 6866"><g style="stroke-width:.025in; stroke:black; fill:none"><polyline points="472,3590 472,9732 " style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round; "></polyline><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,9448 A 4660 4660  0  0  1  8598  9259"></path><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4488,9685 A 4228 4228  0  0  0   472  9732"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:butt;" d="M 4724,3590 A 4241 4241  0  0  1  8598  3496"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,3496  A 4241 4241  0  0  1  4724  3590"></path><path style="stroke:#000000;stroke-width:126;stroke-linecap:round;" d="M 850,9259  A 4507 4507  0  0  1  4724  9448"></path><polyline points="5385,4299 4062,8125" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8598,3496 8598,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="850,3496 850,9259" style="stroke:#000000;stroke-width:126; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="4960,9685 4488,9685" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="3070,4582 1889,6141 3070,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="6418,4582 7600,6141 6418,7700" style="stroke:#000000;stroke-width:300; stroke-linejoin:miter; stroke-linecap:round;"></polyline><polyline points="8976,3590 8976,9732" style="stroke:#000000;stroke-width:174; stroke-linejoin:miter; stroke-linecap:round;"></polyline><path style="stroke:#000000;stroke-width:174;stroke-linecap:butt;" d="M 4960,9685 A 4228 4228  0  0  1  8976  9732"></path></g></svg></div></a><a class="runestone-link" href="https://runestone.academy" title="Runestone Academy"><img class="logo" src="https://runestone.academy/runestone/static/images/RAIcon_cropped.png"></a><a class="mathjax-link" href="https://www.mathjax.org" title="MathJax"><img class="logo" src="https://www.mathjax.org/badge/badge-square-2.png"></a>
</div>
</body>
</html>
